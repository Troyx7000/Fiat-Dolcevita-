{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and Analyzing YouTube Data on Fiat 500 Dolcevita\n",
    "\n",
    "This script utilizes the YouTube Data API and the YouTube Transcript API to collect data on videos related to the Fiat 500 Dolcevita in the United Kingdom. The data collection focuses on gathering video details, comments, and transcripts, followed by basic analysis of the collected data.\n",
    "\n",
    "#### Key Components:\n",
    "\n",
    "1. **YouTube API Initialization**:\n",
    "   - The script initializes the YouTube Data API using a developer API key. This allows interaction with YouTube to search for videos, retrieve video details, and collect comments.\n",
    "\n",
    "2. **Search for Videos**:\n",
    "   - The `search_videos` function is used to search for videos related to the Fiat 500 Dolcevita within a specified date range (2018-2024) in the United Kingdom. The function returns a list of video IDs matching the search criteria.\n",
    "\n",
    "3. **Retrieve Video Details**:\n",
    "   - The `get_video_details` function fetches important details for each video, such as the channel name, publish date, and view count.\n",
    "\n",
    "4. **Collect Comments**:\n",
    "   - The `get_comments` function gathers all top-level comments for each video along with their posting dates. It handles cases where comments are disabled or unavailable.\n",
    "\n",
    "5. **Fetch Transcripts**:\n",
    "   - The `get_transcript` function attempts to retrieve the transcript for each video. If a transcript is not available, an appropriate message is returned.\n",
    "\n",
    "6. **Data Aggregation**:\n",
    "   - The script iterates through the list of video IDs, collecting details, comments, and transcripts for each video. The data is stored in a list of dictionaries, which is then converted to a DataFrame.\n",
    "\n",
    "7. **Save Data**:\n",
    "   - The collected data is saved to a CSV file named `fiat_500_dolcevita_videos_comments.csv`.\n",
    "\n",
    "8. **Basic Analysis**:\n",
    "   - The script performs several analyses on the collected data:\n",
    "     - **Number of Videos Per Year**: Counts the number of videos published each year.\n",
    "     - **Most Viewed Year**: Identifies the year with the highest total views.\n",
    "     - **Most Commented Year**: Determines the year with the most comments.\n",
    "     - **Most Viewed Video**: Finds the video with the highest view count.\n",
    "     - **Most Commented Video**: Identifies the video with the most comments.\n",
    "\n",
    "9. **Display Results**:\n",
    "   - The results of the analysis are printed, including the most viewed and most commented videos, along with their URLs, view counts, and publication details.\n",
    "\n",
    "### Summary:\n",
    "This script automates the process of collecting and analyzing YouTube data related to Fiat 500 Dolcevita, providing insights into the popularity and engagement of videos over time. The basic analysis allows for quick identification of key trends, such as the most popular years for video views and comments, as well as highlighting the top-performing videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your API key\n",
    "api_key = 'AIzaSyDTWxsoLNz04gEgu_Mx4m_C5tQg7o34wYY'\n",
    "\n",
    "# Create a resource object for interacting with the YouTube API\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Function to search for videos about Fiat 500 Dolcevita in the United Kingdom\n",
    "def search_videos(query, start_date, end_date, region_code, max_results=50):\n",
    "    video_ids = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.search().list(\n",
    "            part='snippet',\n",
    "            q=query,\n",
    "            type='video',\n",
    "            publishedAfter=start_date,\n",
    "            publishedBefore=end_date,\n",
    "            regionCode=region_code,\n",
    "            maxResults=max_results,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_id = item['id']['videoId']\n",
    "            video_ids.append(video_id)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return video_ids\n",
    "\n",
    "# Function to get video details (channel name, creation date, view count)\n",
    "def get_video_details(video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet,statistics',\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    video_details = response['items'][0]\n",
    "    channel_title = video_details['snippet']['channelTitle']\n",
    "    publish_date = video_details['snippet']['publishedAt']\n",
    "    view_count = int(video_details['statistics'].get('viewCount', 0))\n",
    "    return channel_title, publish_date, view_count\n",
    "\n",
    "# Function to get all comments for a video along with their posting dates\n",
    "def get_comments(video_id, max_results=100):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                maxResults=max_results,\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                comment_date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "                comments.append({'comment': comment, 'date': comment_date})\n",
    "\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            comments.append({'comment': f\"Comments not available or disabled: {str(e)}\", 'date': None})\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Function to get the transcript for a video\n",
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        transcript = transcript_list.find_transcript(['en'])\n",
    "        return transcript.fetch()\n",
    "    except Exception as e:\n",
    "        return f\"Transcript not available: {str(e)}\"\n",
    "\n",
    "# Define the search term, date range, and region code\n",
    "search_term = 'Fiat 500 Dolcevita'\n",
    "start_date = '2018-01-01T00:00:00Z'  # Start date (ISO 8601 format)\n",
    "end_date = '2024-12-31T23:59:59Z'    # End date (ISO 8601 format)\n",
    "region_code = 'GB'  # Region code for the United Kingdom\n",
    "\n",
    "# Search for videos\n",
    "if __name__ == \"__main__\":\n",
    "    video_ids = search_videos(search_term, start_date, end_date, region_code)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        print(f\"Processing video: {video_url}\")\n",
    "\n",
    "        # Fetch video details\n",
    "        channel_title, publish_date, view_count = get_video_details(video_id)\n",
    "\n",
    "        # Fetch comments\n",
    "        comments = get_comments(video_id)\n",
    "        if any(\"Comments not available or disabled\" in comment['comment'] for comment in comments):\n",
    "            print(\"Comments not available or disabled\")\n",
    "            continue  # Skip videos with comments disabled\n",
    "\n",
    "        # Fetch transcript\n",
    "        transcript = get_transcript(video_id)\n",
    "        if isinstance(transcript, str):\n",
    "            transcript_text = transcript\n",
    "        else:\n",
    "            transcript_text = \" \".join([entry['text'] for entry in transcript])\n",
    "\n",
    "        data.append({\n",
    "            'video_url': video_url,\n",
    "            'channel_title': channel_title,\n",
    "            'publish_date': publish_date,\n",
    "            'view_count': view_count,\n",
    "            'comments': [comment['comment'] for comment in comments],\n",
    "            'comment_dates': [comment['date'] for comment in comments],\n",
    "            'transcript': transcript_text\n",
    "        })\n",
    "\n",
    "    # Save data to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('fiat_500_dolcevita_videos_comments.csv', index=False)\n",
    "    print(\"Data saved to fiat_500_dolcevita_videos.csv\")\n",
    "\n",
    "    # Analysis\n",
    "    df['publish_year'] = pd.to_datetime(df['publish_date']).dt.year\n",
    "\n",
    "    # Number of videos per year\n",
    "    videos_per_year = df['publish_year'].value_counts().sort_index()\n",
    "\n",
    "    # Most viewed year\n",
    "    views_per_year = df.groupby('publish_year')['view_count'].sum()\n",
    "    most_viewed_year = views_per_year.idxmax()\n",
    "    most_viewed_year_views = views_per_year.max()\n",
    "\n",
    "    # Most commented year\n",
    "    comments_per_year = df['publish_year'].apply(lambda x: len(df[df['publish_year'] == x]['comments'].sum()))\n",
    "    most_commented_year = comments_per_year.idxmax()\n",
    "    most_commented_year_comments = comments_per_year.max()\n",
    "\n",
    "    # Most viewed video\n",
    "    most_viewed_video = df.loc[df['view_count'].idxmax()]\n",
    "\n",
    "    # Most commented video\n",
    "    df['comment_count'] = df['comments'].apply(len)\n",
    "    most_commented_video = df.loc[df['comment_count'].idxmax()]\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nNumber of videos per year:\")\n",
    "    print(videos_per_year)\n",
    "\n",
    "    print(f\"\\nYear with the most views: {most_viewed_year} ({most_viewed_year_views} views)\")\n",
    "    print(f\"\\nYear with the most comments: {most_commented_year} ({most_commented_year_comments} comments)\")\n",
    "\n",
    "    print(f\"\\nMost viewed video:\")\n",
    "    print(f\"URL: {most_viewed_video['video_url']}\")\n",
    "    print(f\"Views: {most_viewed_video['view_count']}\")\n",
    "    print(f\"Channel: {most_viewed_video['channel_title']}\")\n",
    "    print(f\"Published: {most_viewed_video['publish_date']}\")\n",
    "\n",
    "    print(f\"\\nMost commented video:\")\n",
    "    print(f\"URL: {most_commented_video['video_url']}\")\n",
    "    print(f\"Comments: {most_commented_video['comment_count']}\")\n",
    "    print(f\"Channel: {most_commented_video['channel_title']}\")\n",
    "    print(f\"Published: {most_commented_video['publish_date']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and Structuring YouTube Comments with Dates\n",
    "\n",
    "In this step, the collected YouTube comments are separated, structured, and organized alongside their respective metadata (such as video URL, channel title, and publish date). This process is essential for further analysis or sentiment evaluation of individual comments.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Load the Dataset**:\n",
    "   - The dataset containing YouTube video details, comments, and comment dates is loaded from the previously saved CSV file (`fiat_500_dolcevita_videos_comments.csv`).\n",
    "\n",
    "2. **Function to Process Comments and Dates**:\n",
    "   - The `process_comments_and_dates` function iterates over each row in the DataFrame, extracting the comments and their corresponding dates.\n",
    "   - For each comment, a new row is created in the processed DataFrame that includes the following details:\n",
    "     - **Video URL**\n",
    "     - **Channel Title**\n",
    "     - **Publish Date** (of the video)\n",
    "     - **View Count**\n",
    "     - **Comment**\n",
    "     - **Comment Date**\n",
    "\n",
    "3. **Data Transformation**:\n",
    "   - The function transforms the comments (which were originally stored as a string representation of lists) into individual rows, each associated with its corresponding comment date. This format allows for easier analysis and manipulation of individual comments.\n",
    "\n",
    "4. **Save the Processed Data**:\n",
    "   - The processed comments, along with their metadata, are saved to a new CSV file (`processed_comments_with_dates.csv`).\n",
    "\n",
    "5. **Preview the Processed Data**:\n",
    "   - The first few rows of the processed DataFrame are displayed to verify the structure and content of the data.\n",
    "\n",
    "### Summary:\n",
    "This processing step organizes the YouTube comments into a more structured format, with each comment paired with its metadata and date. This structured dataset is essential for performing detailed analyses, such as sentiment analysis or temporal trends in viewer engagement and feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/abhishekroy/Downloads/vscode folder/fiat_500_dolcevita_videos_comments.csv'\n",
    "comments_df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to separate and number comments along with their dates\n",
    "def process_comments_and_dates(df):\n",
    "    processed_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        video_url = row['video_url']\n",
    "        channel_title = row['channel_title']\n",
    "        publish_date = row['publish_date']\n",
    "        view_count = row['view_count']\n",
    "        \n",
    "        comments = eval(row['comments'])  # Assuming comments are stored as a string representation of a list\n",
    "        comment_dates = eval(row['comment_dates'])  # Assuming comment dates are stored similarly\n",
    "        \n",
    "        for comment, comment_date in zip(comments, comment_dates):\n",
    "            processed_data.append({\n",
    "                'video_url': video_url,\n",
    "                'channel_title': channel_title,\n",
    "                'publish_date': publish_date,\n",
    "                'view_count': view_count,\n",
    "                'comment': comment,\n",
    "                'comment_date': comment_date\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Process the comments and their dates\n",
    "processed_comments_df = process_comments_and_dates(comments_df)\n",
    "\n",
    "# Save the processed comments to a CSV file\n",
    "output_file_path = 'processed_comments_with_dates.csv'\n",
    "processed_comments_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the processed comments DataFrame\n",
    "print(processed_comments_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Emojis to Text in YouTube Comments\n",
    "\n",
    "In this step, the YouTube comments are further processed by converting any emojis present in the comments into their corresponding text descriptions. This conversion is important for text analysis tasks, ensuring that the sentiment or meaning conveyed by emojis is retained and can be analyzed in a text-based format.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Load the Dataset**:\n",
    "   - The processed comments dataset, which includes individual comments along with their metadata, is loaded from the previously saved CSV file (`processed_comments_with_dates.csv`).\n",
    "\n",
    "2. **Emoji Conversion Function**:\n",
    "   - A function, `convert_emojis_to_text`, is defined to convert any emojis present in the comments to their corresponding text descriptions (e.g., 😊 becomes `:smiley:`). This conversion allows for the retention of meaning conveyed by emojis during text-based analysis.\n",
    "   - The function handles cases where the comment may be a float (e.g., NaN values) by converting them to strings.\n",
    "\n",
    "3. **Apply the Conversion**:\n",
    "   - The `convert_emojis_to_text` function is applied to each comment in the DataFrame, creating a new column `comment_with_text_emojis` that contains the comments with emojis replaced by their text equivalents.\n",
    "\n",
    "4. **Save the Updated Data**:\n",
    "   - The updated DataFrame, now including the text-based emoji representations, is saved to a new CSV file (`comments_with_text_emojis.csv`).\n",
    "\n",
    "5. **Preview the Updated Data**:\n",
    "   - The first few rows of the updated DataFrame are displayed to verify the emoji conversion and overall structure of the data.\n",
    "\n",
    "### Summary:\n",
    "This step enhances the textual representation of YouTube comments by converting emojis into text, ensuring that all elements of the comment are accessible for text-based analysis. The processed dataset is now better suited for subsequent analyses such as sentiment analysis, topic modeling, or other natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/abhishekroy/Downloads/vscode folder/processed_comments_with_dates.csv'  # Replace with your actual file path\n",
    "processed_comments_df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to convert emojis to text\n",
    "def convert_emojis_to_text(comment):\n",
    "    if isinstance(comment, float):\n",
    "        return str(comment)  # Convert float to string\n",
    "    else:\n",
    "        return emoji.demojize(comment)\n",
    "\n",
    "# Apply the function to each comment in the DataFrame\n",
    "processed_comments_df['comment_with_text_emojis'] = processed_comments_df['comment'].apply(convert_emojis_to_text)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = 'comments_with_text_emojis.csv'\n",
    "processed_comments_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(processed_comments_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Preprocessing YouTube Comments\n",
    "\n",
    "In this step, the YouTube comments are thoroughly cleaned and preprocessed to prepare them for further analysis. This includes removing unnecessary tokens, handling emojis, and normalizing the text.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Loading the Dataset**:\n",
    "   - The dataset containing YouTube comments with their metadata and emojis converted to text is loaded from the previously saved CSV file (`comments_with_text_emojis.csv`).\n",
    "\n",
    "2. **Text Cleaning Functions**:\n",
    "   - **Remove HTML Tags and Non-Relevant Tokens**: \n",
    "     - The `remove_html_tags_and_tokens` function removes HTML tags, certain tokens (`br`, `href`, `quot`), URLs, punctuation, digits, and underscores. It also converts the text to lowercase.\n",
    "   - **Tokenization and Lemmatization**:\n",
    "     - Comments are tokenized using NLTK's `word_tokenize` function, and then stopwords are removed. The remaining tokens are lemmatized to their base form using the `WordNetLemmatizer`, ensuring that different forms of a word are treated as the same word.\n",
    "   - **Emoji Conversion**:\n",
    "     - The `convert_emojis_to_text` function converts any emojis in the comments into their corresponding text descriptions, retaining the meaning of emojis in a text-based format.\n",
    "\n",
    "3. **Applying the Cleaning Functions**:\n",
    "   - The functions are applied to the comments in the DataFrame to create two new cleaned columns:\n",
    "     - **`cleaned_comment_original`**: This column contains the cleaned version of the original comments without emoji conversion.\n",
    "     - **`cleaned_comment_with_text_emojis`**: This column contains the cleaned version of the comments after emojis have been converted to text.\n",
    "\n",
    "4. **Saving the Cleaned Data**:\n",
    "   - The cleaned DataFrame, with both the original and emoji-converted cleaned comments, is saved to a new CSV file (`cleaned_comments_with_text_emojis.csv`).\n",
    "\n",
    "5. **Verification**:\n",
    "   - The first few rows of the cleaned DataFrame are displayed to verify the cleaning process.\n",
    "   - The total number of comments after the cleaning process is also printed to ensure that no data was lost during preprocessing.\n",
    "\n",
    "### Summary:\n",
    "This cleaning and preprocessing step ensures that the YouTube comments are in a consistent and normalized format, making them ready for more advanced analyses such as sentiment analysis, topic modeling, or machine learning applications. By handling HTML tags, irrelevant tokens, and emojis, the comments are now cleaner and more standardized, improving the quality of any subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import emoji\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove HTML tags and non-relevant tokens\n",
    "def remove_html_tags_and_tokens(comment):\n",
    "    comment = re.sub(r'<.*?>', ' ', comment)  # Remove HTML tags\n",
    "    comment = re.sub(r'\\bbr\\b', ' ', comment)  # Remove \"br\" tokens\n",
    "    comment = re.sub(r'\\bhref\\b', ' ', comment)  # Remove \"href\" tokens\n",
    "    comment = re.sub(r'\\bquot\\b', ' ', comment)  # Remove \"quot\" tokens\n",
    "    return comment\n",
    "\n",
    "# Function to clean comments\n",
    "def clean_comment(comment):\n",
    "    if pd.isna(comment):\n",
    "        return \"\"\n",
    "    comment = str(comment)  # Ensure the comment is a string\n",
    "    comment = remove_html_tags_and_tokens(comment)  # Remove HTML tags and tokens\n",
    "    comment = re.sub(r'http\\S+|www\\S+|https\\S+', '', comment)  # Remove URLs\n",
    "    comment = re.sub(r'\\W', ' ', comment)  # Remove punctuation\n",
    "    comment = re.sub(r'\\d', '', comment)  # Remove digits\n",
    "    comment = comment.replace('_', ' ')  # Replace underscores with spaces\n",
    "    comment = comment.lower()  # Convert to lowercase\n",
    "    tokens = nltk.word_tokenize(comment)  # Tokenize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]  # Remove stopwords and lemmatize\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Function to convert emojis to text\n",
    "def convert_emojis_to_text(comment):\n",
    "    if isinstance(comment, float):\n",
    "        return str(comment)  # Convert float to string\n",
    "    else:\n",
    "        return emoji.demojize(comment)\n",
    "\n",
    "# Load the DataFrame with comments and dates\n",
    "file_path = '/Users/abhishekroy/Downloads/vscode folder/comments_with_text_emojis.csv'  # Replace with your actual file path\n",
    "comments_df = pd.read_csv(file_path)\n",
    "\n",
    "# Apply the functions to create two cleaned columns\n",
    "comments_df['cleaned_comment_original'] = comments_df['comment'].apply(clean_comment)\n",
    "comments_df['cleaned_comment_with_text_emojis'] = comments_df['comment_with_text_emojis'].apply(lambda x: clean_comment(convert_emojis_to_text(x)))\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = 'cleaned_comments_with_text_emojis.csv'\n",
    "comments_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaning complete. Cleaned comments saved to {output_file_path}.\")\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(comments_df.head())\n",
    "\n",
    "# Check the number of comments after the cleaning process\n",
    "num_comments = comments_df.shape[0]\n",
    "print(f\"Number of comments after cleaning: {num_comments}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating YouTube Comments to English Using DeepL\n",
    "\n",
    "In this step, the YouTube comments, which may contain content in various languages, are translated into English using the DeepL API. This ensures that all comments are in a consistent language for further analysis.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **DeepL API Initialization**:\n",
    "   - The DeepL API is initialized with the provided API key to facilitate the translation of comments from their original language to English (target language: `EN-GB`).\n",
    "\n",
    "2. **Loading the Dataset**:\n",
    "   - The dataset containing cleaned comments, including those with emojis converted to text, is loaded from the previously saved CSV file (`cleaned_comments_with_text_emojis.csv`).\n",
    "\n",
    "3. **Translation Function**:\n",
    "   - A function, `translate_comments_batch`, is defined to translate a batch of comments using the DeepL API. This function handles translation in batches to comply with size limits and avoid rate limiting by the API.\n",
    "   - The `json_size` function is used to calculate the size of a JSON-encoded string to ensure that the API requests do not exceed the maximum allowable request size (128 KiB).\n",
    "\n",
    "4. **Batch Translation Process**:\n",
    "   - Comments are translated in batches to manage the API request size efficiently. A progress bar (`tqdm`) is implemented to track the progress of the translation process.\n",
    "   - A delay is added between batches to avoid triggering rate limits on the API.\n",
    "\n",
    "5. **Handling Remaining Comments**:\n",
    "   - After processing the main batches, any remaining untranslated comments are handled separately to ensure all comments are translated.\n",
    "\n",
    "6. **Saving Translated Comments**:\n",
    "   - The translated comments are added to the DataFrame under a new column, `translated_comments`.\n",
    "   - The updated DataFrame, now including the translated comments, is saved to a new CSV file (`translated_comments_with_text_emojis.csv`).\n",
    "\n",
    "7. **Verification**:\n",
    "   - The first few rows of the updated DataFrame are displayed to verify the translation process and ensure that the comments have been correctly translated.\n",
    "\n",
    "### Summary:\n",
    "This translation step standardizes the language of YouTube comments, converting them all to English using the DeepL API. By doing so, the dataset becomes uniform in language, facilitating more effective text analysis in subsequent steps. The batch processing approach ensures that the translation is handled efficiently, even with API limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Initialize DeepL API credentials\n",
    "api_key = '90880816-06ee-4f7a-8427-83bf5ebee279'  # Use your provided API key\n",
    "translator = deepl.Translator(api_key)\n",
    "\n",
    "# Function to translate a batch of comments using DeepL API\n",
    "def translate_comments_batch(comments, target_lang='EN-GB'):\n",
    "    try:\n",
    "        translations = translator.translate_text(comments, target_lang=target_lang)\n",
    "        return [translation.text for translation in translations]\n",
    "    except deepl.DeepLException as e:\n",
    "        print(f\"Error in translation: {e}\")\n",
    "        return [''] * len(comments)  # Return empty strings for this batch\n",
    "\n",
    "# Function to calculate the size of a JSON-encoded string\n",
    "def json_size(data):\n",
    "    return len(json.dumps(data).encode('utf-8'))\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/abhishekroy/Downloads/vscode folder/cleaned_comments_with_text_emojis.csv'  # Replace with your actual file path\n",
    "processed_comments_df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure all comments are strings and clean\n",
    "column_name = 'cleaned_comment_with_text_emojis'  # Use the correct column name\n",
    "processed_comments_df[column_name] = processed_comments_df[column_name].apply(lambda x: str(x) if not pd.isna(x) else '')\n",
    "\n",
    "# Batch processing settings\n",
    "max_request_size = 128 * 1024  # 128 KiB\n",
    "translated_comments = []\n",
    "\n",
    "# Translate the comments with progress bar\n",
    "i = 0\n",
    "total_comments = len(processed_comments_df)\n",
    "with tqdm(total=total_comments, desc=\"Translating comments\") as pbar:\n",
    "    while i < total_comments:\n",
    "        batch_comments = []\n",
    "        current_size = 0\n",
    "        \n",
    "        while i < total_comments and current_size < max_request_size:\n",
    "            comment = processed_comments_df[column_name][i]\n",
    "            comment_size = json_size({\"text\": [comment], \"target_lang\": \"EN-GB\"})\n",
    "            if current_size + comment_size < max_request_size:\n",
    "                batch_comments.append(comment)\n",
    "                current_size += comment_size\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        translated_batch = translate_comments_batch(batch_comments)\n",
    "        translated_comments.extend(translated_batch)\n",
    "        pbar.update(len(batch_comments))\n",
    "        time.sleep(1)  # Add a delay between batches to avoid rate limiting\n",
    "\n",
    "# Add remaining untranslated comments if any\n",
    "if i < total_comments:\n",
    "    remaining_comments = processed_comments_df[column_name][i:].tolist()\n",
    "    translated_batch = translate_comments_batch(remaining_comments)\n",
    "    translated_comments.extend(translated_batch)\n",
    "\n",
    "processed_comments_df['translated_comments'] = translated_comments\n",
    "\n",
    "# Save the DataFrame with translated comments to a new CSV file\n",
    "output_file_path = 'translated_comments_with_text_emojis.csv'\n",
    "processed_comments_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Translation complete. Translated comments saved to {output_file_path}.\")\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(processed_comments_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating YouTube Comments with Language Detection and DeepL\n",
    "\n",
    "In this step, the YouTube comments, specifically those in a column containing only plain text without emojis, were processed to detect their source languages and then translated into English using the DeepL API. This approach was taken to effectively capture topics during subsequent analysis.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **DeepL API Initialization**:\n",
    "   - The DeepL API was initialized using the provided API key, enabling the translation of comments from various source languages into English (`EN-GB`).\n",
    "\n",
    "2. **Loading and Preparing the Dataset**:\n",
    "   - The dataset containing cleaned comments was loaded from the previously saved CSV file (`cleaned_comments_with_text_emojis.csv`).\n",
    "   - The focus was on a specific column (`cleaned_comment_original`) containing only plain text without emojis to ensure effective topic capture in the next analysis steps.\n",
    "   - All comments were ensured to be in string format, and empty or whitespace-only comments were filtered out to focus only on meaningful content.\n",
    "\n",
    "3. **Language Detection**:\n",
    "   - A function, `detect_language`, was used to detect the source language of each comment using the `langdetect` library.\n",
    "   - Comments with unrecognized languages were labeled as 'unknown'.\n",
    "\n",
    "4. **Filtering Supported Languages**:\n",
    "   - Only comments in languages supported by DeepL were retained for translation. This included languages such as German (`de`), French (`fr`), Spanish (`es`), and others.\n",
    "\n",
    "5. **Batch Translation Process**:\n",
    "   - Comments were translated in batches, with the source language specified for each comment to ensure accurate translation.\n",
    "   - The process used a progress bar (`tqdm`) to track the progress of the translation, and a delay was introduced between batches to avoid exceeding the API's rate limits.\n",
    "\n",
    "6. **Handling Remaining Comments**:\n",
    "   - After the main batch processing, any remaining untranslated comments were processed in a final batch to ensure that all supported comments were translated.\n",
    "\n",
    "7. **Saving the Translated Comments**:\n",
    "   - The translated comments were stored in a new column, `translated_plain_texts`, within the DataFrame.\n",
    "   - The updated DataFrame, including the newly translated comments, was saved to a CSV file (`translated_comments_with_plain_texts.csv`).\n",
    "\n",
    "8. **Verification**:\n",
    "   - The first few rows of the updated DataFrame were displayed to verify the translation process and ensure that comments were translated correctly.\n",
    "\n",
    "### Summary:\n",
    "This translation process enhanced the dataset by ensuring that all comments in the plain text column (without emojis) were translated into English. This was crucial for effectively capturing topics during subsequent analysis. By detecting and specifying the source language, the accuracy of the translations was improved. The final dataset, saved with a new column containing plain translated texts, is now better suited for uniform analysis across all comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from langdetect import detect, DetectorFactory, LangDetectException\n",
    "\n",
    "# Set seed for reproducibility in language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Initialize DeepL API credentials\n",
    "api_key = '90880816-06ee-4f7a-8427-83bf5ebee279'  # Use your provided API key\n",
    "translator = deepl.Translator(api_key)\n",
    "\n",
    "# Function to translate a batch of comments using DeepL API\n",
    "def translate_comments_batch(comments, source_langs, target_lang='EN-GB'):\n",
    "    try:\n",
    "        translations = []\n",
    "        for comment, source_lang in zip(comments, source_langs):\n",
    "            translation = translator.translate_text(comment, source_lang=source_lang, target_lang=target_lang)\n",
    "            translations.append(translation.text)\n",
    "        return translations\n",
    "    except deepl.DeepLException as e:\n",
    "        print(f\"Error in translation: {e}\")\n",
    "        return [''] * len(comments)  # Return empty strings for this batch\n",
    "\n",
    "# Function to calculate the size of a JSON-encoded string\n",
    "def json_size(data):\n",
    "    return len(json.dumps(data).encode('utf-8'))\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/abhishekroy/Downloads/vscode folder/cleaned_comments_with_text_emojis.csv'  # Replace with your actual file path\n",
    "processed_comments_df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure all comments are strings and clean\n",
    "column_name = 'cleaned_comment_original'  # Use the correct column name\n",
    "processed_comments_df[column_name] = processed_comments_df[column_name].apply(lambda x: str(x) if not pd.isna(x) else '')\n",
    "\n",
    "# Filter out empty or whitespace-only comments\n",
    "processed_comments_df = processed_comments_df[processed_comments_df[column_name].str.strip() != '']\n",
    "\n",
    "# Detect the source language of each comment\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "\n",
    "processed_comments_df['source_lang'] = processed_comments_df[column_name].apply(detect_language)\n",
    "\n",
    "# Supported languages by DeepL\n",
    "supported_languages = ['bg', 'zh', 'cs', 'da', 'nl', 'en', 'et', 'fi', 'fr', 'de', 'el', 'hu', 'it', 'ja', \n",
    "                       'lv', 'lt', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'es', 'sv']\n",
    "\n",
    "# Filter out unsupported languages\n",
    "processed_comments_df = processed_comments_df[processed_comments_df['source_lang'].isin(supported_languages)]\n",
    "\n",
    "# Batch processing settings\n",
    "max_request_size = 128 * 1024  # 128 KiB\n",
    "translated_comments = []\n",
    "\n",
    "# Translate the comments with progress bar\n",
    "i = 0\n",
    "total_comments = len(processed_comments_df)\n",
    "with tqdm(total=total_comments, desc=\"Translating comments\") as pbar:\n",
    "    while i < total_comments:\n",
    "        batch_comments = []\n",
    "        batch_source_langs = []\n",
    "        current_size = 0\n",
    "        \n",
    "        while i < total_comments and current_size < max_request_size:\n",
    "            comment = processed_comments_df[column_name].iloc[i]\n",
    "            source_lang = processed_comments_df['source_lang'].iloc[i]\n",
    "            if source_lang == 'unknown':\n",
    "                i += 1\n",
    "                continue\n",
    "            comment_size = json_size({\"text\": [comment], \"source_lang\": source_lang, \"target_lang\": \"EN-GB\"})\n",
    "            if current_size + comment_size < max_request_size:\n",
    "                batch_comments.append(comment)\n",
    "                batch_source_langs.append(source_lang)\n",
    "                current_size += comment_size\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        translated_batch = translate_comments_batch(batch_comments, batch_source_langs)\n",
    "        translated_comments.extend(translated_batch)\n",
    "        pbar.update(len(batch_comments))\n",
    "        time.sleep(1)  # Add a delay between batches to avoid rate limiting\n",
    "\n",
    "# Add remaining untranslated comments if any\n",
    "if i < total_comments:\n",
    "    remaining_comments = processed_comments_df[column_name].iloc[i:].tolist()\n",
    "    remaining_source_langs = processed_comments_df['source_lang'].iloc[i:].tolist()\n",
    "    translated_batch = translate_comments_batch(remaining_comments, remaining_source_langs)\n",
    "    translated_comments.extend(translated_batch)\n",
    "\n",
    "processed_comments_df['translated_plain_texts'] = translated_comments\n",
    "\n",
    "# Save the DataFrame with translated comments to a new CSV file\n",
    "output_file_path = 'translated_comments_with_plain_texts.csv'\n",
    "processed_comments_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Translation complete. Translated comments saved to {output_file_path}.\")\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(processed_comments_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_url</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>view_count</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>comment_with_text_emojis</th>\n",
       "      <th>cleaned_comment_original</th>\n",
       "      <th>cleaned_comment_with_text_emojis</th>\n",
       "      <th>source_lang</th>\n",
       "      <th>translated_plain_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8.696000e+03</td>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8696</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>272</td>\n",
       "      <td>226</td>\n",
       "      <td>272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7699</td>\n",
       "      <td>8058</td>\n",
       "      <td>7699</td>\n",
       "      <td>7557</td>\n",
       "      <td>7609</td>\n",
       "      <td>23</td>\n",
       "      <td>7524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.youtube.com/watch?v=WaG4QoovK78</td>\n",
       "      <td>Der Held</td>\n",
       "      <td>2020-10-30T16:00:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7 φορές</td>\n",
       "      <td>2019-09-07T17:54:08Z</td>\n",
       "      <td>7 φορές</td>\n",
       "      <td>φορές</td>\n",
       "      <td>φορές</td>\n",
       "      <td>it</td>\n",
       "      <td>times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>210</td>\n",
       "      <td>203</td>\n",
       "      <td>1559</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.465946e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.338595e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.730000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.580100e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.135380e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.022790e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.546634e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          video_url channel_title  \\\n",
       "count                                          8696          8696   \n",
       "unique                                          272           226   \n",
       "top     https://www.youtube.com/watch?v=WaG4QoovK78      Der Held   \n",
       "freq                                            798           798   \n",
       "mean                                            NaN           NaN   \n",
       "std                                             NaN           NaN   \n",
       "min                                             NaN           NaN   \n",
       "25%                                             NaN           NaN   \n",
       "50%                                             NaN           NaN   \n",
       "75%                                             NaN           NaN   \n",
       "max                                             NaN           NaN   \n",
       "\n",
       "                publish_date    view_count  comment          comment_date  \\\n",
       "count                   8696  8.696000e+03     8696                  8696   \n",
       "unique                   272           NaN     7699                  8058   \n",
       "top     2020-10-30T16:00:07Z           NaN  7 φορές  2019-09-07T17:54:08Z   \n",
       "freq                     798           NaN      147                     4   \n",
       "mean                     NaN  1.465946e+05      NaN                   NaN   \n",
       "std                      NaN  2.338595e+05      NaN                   NaN   \n",
       "min                      NaN  1.730000e+02      NaN                   NaN   \n",
       "25%                      NaN  5.580100e+04      NaN                   NaN   \n",
       "50%                      NaN  1.135380e+05      NaN                   NaN   \n",
       "75%                      NaN  2.022790e+05      NaN                   NaN   \n",
       "max                      NaN  2.546634e+06      NaN                   NaN   \n",
       "\n",
       "       comment_with_text_emojis cleaned_comment_original  \\\n",
       "count                      8696                     8696   \n",
       "unique                     7699                     7557   \n",
       "top                     7 φορές                    φορές   \n",
       "freq                        147                      210   \n",
       "mean                        NaN                      NaN   \n",
       "std                         NaN                      NaN   \n",
       "min                         NaN                      NaN   \n",
       "25%                         NaN                      NaN   \n",
       "50%                         NaN                      NaN   \n",
       "75%                         NaN                      NaN   \n",
       "max                         NaN                      NaN   \n",
       "\n",
       "       cleaned_comment_with_text_emojis source_lang translated_plain_texts  \n",
       "count                              8696        8696                   8692  \n",
       "unique                             7609          23                   7524  \n",
       "top                               φορές          it                  times  \n",
       "freq                                203        1559                    319  \n",
       "mean                                NaN         NaN                    NaN  \n",
       "std                                 NaN         NaN                    NaN  \n",
       "min                                 NaN         NaN                    NaN  \n",
       "25%                                 NaN         NaN                    NaN  \n",
       "50%                                 NaN         NaN                    NaN  \n",
       "75%                                 NaN         NaN                    NaN  \n",
       "max                                 NaN         NaN                    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/abhishekroy/Downloads/vscode folder/translated_comments_with_plain_texts.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "descriptive_stats = df.describe(include='all')\n",
    "\n",
    "# Display the descriptive statistics\n",
    "descriptive_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling and Coherence Analysis of YouTube Comments\n",
    "\n",
    "In this step, topic modeling is performed on the translated YouTube comments, focusing on effectively capturing underlying themes using n-grams and evaluating the model’s performance with coherence scores.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Loading and Preparing the Dataset**:\n",
    "   - The dataset containing translated comments was loaded from the CSV file (`translated_comments_with_plain_texts.csv`).\n",
    "   - Any rows with missing values in the `translated_plain_texts` column were removed to ensure clean data for analysis.\n",
    "\n",
    "2. **Stopwords Removal and Text Preprocessing**:\n",
    "   - English stopwords were removed to eliminate common, non-informative words.\n",
    "   - The comments were tokenized, and bigrams and trigrams were created using Gensim's `Phrases` model. This helps capture meaningful phrases and context within the comments.\n",
    "\n",
    "3. **Creating Dictionary and Corpus**:\n",
    "   - A Gensim `Dictionary` was created from the trigram texts to map each word to a unique ID.\n",
    "   - The corpus was constructed as a Bag-of-Words (BoW) representation for each document.\n",
    "\n",
    "4. **TF-IDF Vectorization**:\n",
    "   - The comments were vectorized using TF-IDF (Term Frequency-Inverse Document Frequency) to emphasize terms that are unique and significant across documents.\n",
    "\n",
    "5. **Building and Evaluating LDA Models**:\n",
    "   - Multiple LDA (Latent Dirichlet Allocation) models were trained with varying numbers of topics (from 2 to 10) to discover latent topics.\n",
    "   - Coherence scores, which measure the interpretability of topics, were calculated for each model using Gensim's `CoherenceModel`.\n",
    "\n",
    "6. **Visualizing Coherence Scores**:\n",
    "   - The coherence scores were plotted against the number of topics to identify the optimal number of topics with the highest coherence score.\n",
    "\n",
    "7. **Results**:\n",
    "   - The number of topics corresponding to the highest coherence score was identified as the optimal choice.\n",
    "   - A summary table of coherence scores for each number of topics was generated for reference.\n",
    "\n",
    "### Summary:\n",
    "This topic modeling step identified the optimal number of topics within the YouTube comments by evaluating coherence scores. The use of n-grams (bigrams and trigrams) helped capture contextual phrases, improving the quality of the topics generated. The final output includes a model that can effectively reveal underlying themes in the comments, guiding further analysis and interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhishekroy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 8/8 [01:06<00:00,  8.32s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num_Topics  Coherence_Score\n",
      "0           2         0.459440\n",
      "1           3         0.469979\n",
      "2           4         0.437654\n",
      "3           5         0.479499\n",
      "4           6         0.473573\n",
      "5           7         0.471985\n",
      "6           8         0.459163\n",
      "7           9         0.462100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# Download stopwords if not already available\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the translated dataset\n",
    "file_path = 'translated_comments_with_plain_texts.csv'  # Update with the correct path\n",
    "translated_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the dataset has no NaN values in the 'translated_plain_texts' column\n",
    "translated_data = translated_data.dropna(subset=['translated_plain_texts'])\n",
    "\n",
    "# Extract the comments\n",
    "comments = translated_data['translated_plain_texts'].tolist()\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "comments = [remove_stopwords(comment) for comment in comments]\n",
    "\n",
    "# Convert comments to a list of token lists\n",
    "texts = [comment.split() for comment in comments]\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "bigram = Phrases(texts, min_count=5, threshold=100)\n",
    "trigram = Phrases(bigram[texts], threshold=100)\n",
    "\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "# Form trigrams\n",
    "texts_trigram = make_trigrams(texts)\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(texts_trigram)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts_trigram]\n",
    "\n",
    "# Function to compute coherence values for various numbers of topics\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in tqdm(range(start, limit, step)):\n",
    "        model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "        model.fit(tfidf_matrix)\n",
    "        model_list.append(model)\n",
    "        topics = []\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            top_words = [tf_feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "            topics.append(top_words)\n",
    "        coherencemodel = CoherenceModel(topics=topics, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "# Vectorize the text using TF-IDF with n-grams\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english', ngram_range=(1, 3))\n",
    "tfidf_matrix = vectorizer.fit_transform(comments)\n",
    "tf_feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Compute coherence values\n",
    "start = 2\n",
    "limit = 10\n",
    "step = 1\n",
    "num_top_words = 15\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary, corpus, texts_trigram, limit, start, step)\n",
    "\n",
    "# Plot coherence scores\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"Coherence Scores for Different Number of Topics (Trigrams)\")\n",
    "plt.show()\n",
    "\n",
    "# Display coherence scores\n",
    "coherence_scores_df = pd.DataFrame({'Num_Topics': x, 'Coherence_Score': coherence_values})\n",
    "print(coherence_scores_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling with Trigrams After Removing Unrelated Words\n",
    "\n",
    "In this step, we revisited the topic modeling process by focusing exclusively on trigrams and further refined the text data by removing unrelated words. This approach helps in generating more meaningful and relevant topics from the YouTube comments.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Loading and Preparing the Dataset**:\n",
    "   - The dataset containing translated comments was loaded from the CSV file (`translated_comments_with_plain_texts.csv`).\n",
    "   - Comments with missing values in the `translated_plain_texts` column were removed to ensure clean data.\n",
    "\n",
    "2. **Stopwords and Unrelated Words Removal**:\n",
    "   - A comprehensive list of stopwords and unrelated words was defined, including common English stopwords and specific words or phrases deemed irrelevant for topic modeling.\n",
    "   - The comments were cleaned by removing these stopwords and unrelated words, resulting in a more focused and relevant dataset.\n",
    "\n",
    "3. **Tokenization and N-gram Modeling**:\n",
    "   - The cleaned comments were tokenized into words.\n",
    "   - **Bigrams and Trigrams** were generated using Gensim’s `Phrases` model to capture multi-word expressions and phrases that provide additional context.\n",
    "   - Trigrams were created by first forming bigrams and then combining them into three-word phrases.\n",
    "\n",
    "4. **Converting N-grams Back to Text**:\n",
    "   - The resulting bigrams and trigrams were converted back into text format for use in the LDA (Latent Dirichlet Allocation) modeling process.\n",
    "\n",
    "5. **Topic Modeling with LDA**:\n",
    "   - LDA was performed on the trigram-based comments using the `TfidfVectorizer` for text vectorization. The process included:\n",
    "     - **TF-IDF Vectorization**: Converting the text into a TF-IDF matrix that captures the importance of terms across documents.\n",
    "     - **LDA Model**: Applying LDA to uncover latent topics within the trigram data, with the number of topics set to 5.\n",
    "     - **Topic Extraction**: Extracting the top 50 words for each topic to identify the main themes.\n",
    "   \n",
    "6. **Saving and Analyzing Results**:\n",
    "   - The top words for each topic were saved to a CSV file (`lda_topics_trigrams_cleaned.csv`).\n",
    "   - The document-topic distribution, which indicates the probability distribution of topics across the comments, was also saved for further analysis (`doc_topic_dist_lda_topics_trigrams_cleaned.csv`).\n",
    "\n",
    "7. **Summary of Outputs**:\n",
    "   - **Topics Identified**: The main themes were extracted from the YouTube comments, focusing on relevant and meaningful content.\n",
    "   - **Document-Topic Distribution**: The model provided insight into how comments are distributed across the identified topics.\n",
    "\n",
    "### Summary:\n",
    "By refining the text data to remove unrelated words and focusing on trigrams, this step aimed to improve the quality and relevance of the topics generated through LDA. The result is a set of well-defined themes that better represent the underlying discussions in the YouTube comments. These topics can be used for deeper analysis, such as sentiment analysis or identifying key discussion points related to the Fiat 500 Dolcevita.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhishekroy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trigrams (5 topics):\n",
      "Topic 1: i_ ve heard, roof close automatically, expensive small car, car drive city, city car city, daughter year old, think i_ ll, i_ sorry i_, drive small car, best selling car, new electric version, fun car drive, automatic anti trap_protection, cylinder turbo engine, car fun drive, car costs buy, complicated engine fix, install anti trap_protection, gas hand thecar, honorary traffic_jam leader, poor handling steering_wheel, wife year ago, bigger power bank, prefer normal roof, metres think swif, fiat mini hybrid, bought second car, brouillete million parle, wach fiha motour, got fiat car, seats sit seat, kia ceed gt, keine arocs reifen, car motorway bicycle, iphone pro max, i_ ve fiat, azul welcome akbou, use engine oil, sub let goooo, viva italia holidays, new fiat hybrid, bought car wife, know new fiat, small car fiat, lpg version better, year bought new, uno gives laps, vous paserez innaperçus, close doors inside, know manual hybrid\n",
      "Topic 2: small city car, rear wheel drive, internal combustion engine, i_ ve driving, said phrase times, phrase heard times, soon start_european_tour year, start_european_tour year old, i_ ll look, car long time, small cars really, dream come true, times heard phrase, use clean engine, car soon start_european_tour, brand new fiat, consumes lot fuel, mi laik por, really presenter hats, drive car hp, people drive big, battery seat danger, i_ ll stick, bezzaaaff adel bouira, that_ think think, car automotive dream, tide os tides, certainly consumption curious, think consumption air_conditioning, jib polo shelves, there_ dog god, i_ ve understood, short clear giuliano, girl car i_, consumes average litre, pure electric version, car driving town, car city driving, make model automatic_gearbox, car women car, car young girl, bienvenue tizi ouzou, big man small, man small car, business europe july, absolutely rubbish switches, semiautomatic absolutely rubbish, rubbish switches driving, fiat wondering car, maybe second car\n",
      "Topic 3: i_ ve following, times i_ m_going, video really enjoyed, ask stupid questions, liquid use clean, new cylinder engine, car consumes fuel, spray clean engine, renault clio captur, bought year old, second car family, i_ ve seen, seat compartment seat, puts smile face, parle_kabyle bravo turbo_dz, problems shifting gears, db comfortable price, hire car mallorca, end decided corsa, funeral bells background, bought year ago, literally dream car, automatic_gearbox available algeria, abnormal clutch release, bosch windscreen_wiper blades, collected thursday spectacular, long car fiat, women passionate cars, car driver think, dechra hadik wsemha, driving fiat bj, kind course enormous, makes lot noise, mrehba_bik ndna béjaïa, long test honest, year old expensive, auto review hero, fiat bravo jet, drive long time, review mini needed, said couple times, times phrase luck, second hand car, following long time, ve following long, moderate driving style, probably buy car, twin cylinder twinair, mild hybrid really, takes getting used\n",
      "Topic 4: i_ ve driven, i_ ve bought, comes donkey dog, battery driver seat, left knee driver, check tyre pressures, fixed glass sunroof, gearbox manual gearbox, smokes average city, anti trap device, car test drive, real hybrid car, buying new car, car woman car, batteries starter motors, women car doors, kwh battery exaggerated, walk joking fiat, light years competition, city continuous stop, chhal moteur taha, bought fiat car, petrol engine litres, car forza italia, battery starter motor, jiblns clion faracha, car look cute, times merry christmas, girl link girl, i_ ll say, white red roof, jeep grand cherokee, old interiors economies, opel_adam sold stock, cars expensive city, voice rustam vakhidov, glass_roof lounge version, heard times video, cylinder naturally_aspirated engine, je sais quoi, fiat punto evo, engine grande punto, fiat second car, small cars drive, magnificent ivory seats, seat height adjustment, i_ ve tried, small car car, mild hybrid technology, car i_ ve\n",
      "Topic 5: buy new car, cute little car, phrase said times, i_ d_rather buy, really fun drive, car year ago, ideal city car, car i_ ve, test drive fiat, buy used car, phrase_environmentally_friendly heard times, hybrid mild hybrid, automatic manual gearboxes, lovely car make, watched till end, buy bigger car, long term consumption, big small car, car looks quite, fiat seatbelt_friend fiat, medium long distances, faster country road, fiat stand fix, car waste money, colour rosso passionne, option adore car, video dacia_sandero logan, davide saturday morning, uconnect live mycar, aerotwin wiper_blades bosch, video fiat hybrid, buy fiat look, times said video, car want fast, drive rental car, think i_ m_going, mobile_phone car radio, city car little, times heard phrase_environmentally_friendly, city car fiat, car mild hybrid, sequential manual gearbox, we_ ve got, cars small cars, comprehensive insurance year, choice small car, bike endna grid, fiat rental car, i_ ve waiting, use gear acceleration\n",
      "Topic modeling complete. Topics saved to lda_topics_trigrams_cleaned.csv.\n",
      "Document-topic distribution saved to doc_topic_dist_lda_topics_trigrams_cleaned.csv.\n",
      "                0                         1                           2   \\\n",
      "0      i_ ve heard  roof close automatically         expensive small car   \n",
      "1   small city car          rear wheel drive  internal combustion engine   \n",
      "2  i_ ve following          times i_ m_going        video really enjoyed   \n",
      "3     i_ ve driven              i_ ve bought            comes donkey dog   \n",
      "4      buy new car           cute little car           phrase said times   \n",
      "\n",
      "                     3                  4                     5   \\\n",
      "0        car drive city      city car city     daughter year old   \n",
      "1         i_ ve driving  said phrase times    phrase heard times   \n",
      "2  ask stupid questions   liquid use clean   new cylinder engine   \n",
      "3   battery driver seat   left knee driver  check tyre pressures   \n",
      "4       i_ d_rather buy   really fun drive          car year ago   \n",
      "\n",
      "                              6                             7   \\\n",
      "0                    think i_ ll                   i_ sorry i_   \n",
      "1  soon start_european_tour year  start_european_tour year old   \n",
      "2              car consumes fuel            spray clean engine   \n",
      "3            fixed glass sunroof        gearbox manual gearbox   \n",
      "4                 ideal city car                     car i_ ve   \n",
      "\n",
      "                    8                 9   ...                 40  \\\n",
      "0      drive small car  best selling car  ...    new fiat hybrid   \n",
      "1           i_ ll look     car long time  ...     car young girl   \n",
      "2  renault clio captur   bought year old  ...  said couple times   \n",
      "3  smokes average city  anti trap device  ...     fiat punto evo   \n",
      "4      test drive fiat      buy used car  ...    car mild hybrid   \n",
      "\n",
      "                          41               42                   43  \\\n",
      "0            bought car wife    know new fiat       small car fiat   \n",
      "1       bienvenue tizi ouzou    big man small        man small car   \n",
      "2          times phrase luck  second hand car  following long time   \n",
      "3        engine grande punto  fiat second car     small cars drive   \n",
      "4  sequential manual gearbox       we_ ve got      cars small cars   \n",
      "\n",
      "                             44                           45  \\\n",
      "0            lpg version better              year bought new   \n",
      "1          business europe july  absolutely rubbish switches   \n",
      "2             ve following long       moderate driving style   \n",
      "3       magnificent ivory seats       seat height adjustment   \n",
      "4  comprehensive insurance year             choice small car   \n",
      "\n",
      "                                 46                        47  \\\n",
      "0                    uno gives laps   vous paserez innaperçus   \n",
      "1  semiautomatic absolutely rubbish  rubbish switches driving   \n",
      "2                  probably buy car     twin cylinder twinair   \n",
      "3                       i_ ve tried             small car car   \n",
      "4                   bike endna grid           fiat rental car   \n",
      "\n",
      "                       48                     49  \n",
      "0      close doors inside     know manual hybrid  \n",
      "1      fiat wondering car       maybe second car  \n",
      "2      mild hybrid really     takes getting used  \n",
      "3  mild hybrid technology              car i_ ve  \n",
      "4           i_ ve waiting  use gear acceleration  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "          0         1         2         3         4\n",
      "0  0.073226  0.707095  0.073226  0.073226  0.073227\n",
      "1  0.200000  0.200000  0.200000  0.200000  0.200000\n",
      "2  0.200000  0.200000  0.200000  0.200000  0.200000\n",
      "3  0.200000  0.200000  0.200000  0.200000  0.200000\n",
      "4  0.200000  0.200000  0.200000  0.200000  0.200000\n",
      "Coherence Score: 0.519683354617946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el242476394413456135561814\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el242476394413456135561814_data = {\"mdsDat\": {\"x\": [0.20964191944598667, 0.17164265777261783, -0.2690376143081365, -0.0023631357700593814, -0.10988382714040872], \"y\": [-0.061264046370948295, -0.042215781390096886, -0.16525843315800584, 0.04797955755251715, 0.22075870336653375], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [52.87109917657325, 19.840462504672036, 9.658398385689162, 9.492916224421634, 8.137123708643909]}, \"tinfo\": {\"Term\": [\"video\", \",\", \".\", \"car\", \"e\", \"much\", \"times\", \"i\", \"electric\", \"hybrid\", \"c'est\", \"engine\", \"je\", \"'s\", \"n't\", \"pa\", \"test\", \"seat\", \"little\", \"battery\", \"think\", \"go\", \"come\", \"auto\", \"one\", \"uconnect\", \"ca\", \"get\", \"know\", \"abarth\", \"times\", \"years\", \"many\", \"automatic\", \"hybrid\", \"girl\", \"petrol\", \"thousand\", \"engines\", \"cost\", \"ago\", \"greetings\", \"range\", \"although\", \"hope\", \"choice\", \"-\", \"available\", \"heard\", \"performance\", \"kilometres\", \"often\", \"certainly\", \"transmission\", \"buying\", \"example\", \"friendly\", \"ideal\", \"whole\", \"mild\", \"instead\", \"engine\", \"cylinder\", \"everyone\", \"buy\", \"full\", \"first\", \",\", \"wanted\", \"new\", \"manual\", \"fiat\", \"would\", \"hp\", \"car\", \"also\", \"e\", \"really\", \"version\", \"drive\", \"cars\", \".\", \"small\", \"one\", \"always\", \"'s\", \"well\", \"already\", \"city\", \"still\", \"consumption\", \"video\", \"much\", \"little\", \"i\", \"even\", \"'m\", \"know\", \"looks\", \"n't\", \"w\", \"'d\", \"xd\", \"mobile\", \"red\", \"book\", \"beam\", \"changes\", \"german\", \"answer\", \"nice\", \"water\", \"doors\", \"brother\", \"shopping\", \"likes\", \"link\", \"generally\", \"moves\", \"head\", \"dad\", \"we\", \"max\", \"music\", \"all\", \"'re\", \"shift\", \"shifting\", \"sometimes\", \"device\", \"ca\", \"colour\", \"green\", \"phone\", \"wheel\", \"cute\", \"someone\", \"cm\", \"problem\", \"feel\", \"go\", \"back\", \"much\", \"i\", \".\", \"gear\", \"car\", \"expensive\", \"get\", \"think\", \",\", \"one\", \"price\", \"know\", \"right\", \"driving\", \"see\", \"even\", \"city\", \"would\", \"bought\", \"fiat\", \"cars\", \"drive\", \"c'est\", \"je\", \"auto\", \"voiture\", \"vous\", \"j'ai\", \"coffre\", \"du\", \"android\", \"belle\", \"moi\", \"petite\", \"vid\\u00e9o\", \"fiha\", \"trop\", \"explained\", \"pa\", \"tiphaine\", \"suis\", \"enfants\", \"mi\", \"bon\", \"vacances\", \"grand\", \"lo\", \"avon\", \"con\", \"voitures\", \"por\", \"prix\", \"connected\", \"in\\u00e8s\", \"place\", \"bonne\", \"million\", \"e\", \"fiat\", \"test\", \"review\", \"video\", \"passenger\", \"gears\", \"compartment\", \"matter\", \"stellantis\", \"info\", \"bro\", \"generation\", \"conditioning\", \"sounds\", \"automatically\", \"transport\", \"suitcase\", \"wagon\", \"twice\", \"lenticular\", \"nav\", \"hour\", \"eh\", \"disinfected\", \"board\", \"function\", \"metres\", \"turbocharged\", \"bulbs\", \"confirm\", \"hair\", \"placed\", \"application\", \"gasoline\", \"stick\", \"removed\", \"li\", \"tipo\", \"connect\", \"cross\", \"uconnect\", \"women\", \"radio\", \"soon\", \"seat\", \"box\", \"led\", \"abarth\", \"driver\", \"position\", \"put\", \"live\", \"'s\", \"little\", \"rear\", \"start\", \"car\", \"consumes\", \"pretty\", \"front\", \"e\", \"must\", \"engine\", \"video\", \"without\", \"fiat\", \"one\", \"play\", \"evening\", \"luck\", \"app\", \"licence\", \"iphone\", \"continuation\", \"episode\", \"wipers\", \"comments\", \"update\", \"wiper\", \"mafia\", \"protection\", \"conso\", \"ana\", \"installed\", \"regards\", \"exit\", \"minute\", \"pull\", \"maps\", \"kwh\", \"minutes\", \"chi\", \"allah\", \"bosch\", \"starts\", \"socialism\", \"date\", \"missing\", \"voice\", \"map\", \"plate\", \"motor\", \"video\", \"key\", \"come\", \"help\", \"windscreen\", \"roof\", \"uconnect\", \"please\", \"electric\", \"gives\", \"content\", \"battery\", \"says\", \"bravo\", \"get\", \"fiat\", \"works\", \"yes\", \"see\"], \"Freq\": [629.0, 2221.0, 1202.0, 2281.0, 565.0, 512.0, 456.0, 482.0, 243.0, 475.0, 113.0, 531.0, 87.0, 382.0, 115.0, 79.0, 209.0, 145.0, 354.0, 133.0, 323.0, 258.0, 112.0, 67.0, 796.0, 85.0, 132.0, 292.0, 308.0, 177.0, 455.9519428467767, 225.9229263956312, 185.06457726569417, 169.10333474683847, 473.53880258668426, 144.83657027334797, 116.65600569860693, 92.99451158583838, 87.69857268961525, 85.12185476610927, 77.88607238620489, 74.77766635702518, 68.55985317954948, 63.91155075365132, 61.43334920818398, 60.7654338187594, 58.82287479947517, 57.22866769069733, 55.79583472647295, 55.9951200005619, 58.95513514872768, 54.32709912794017, 50.14142323117708, 47.86964931899405, 46.813584405692836, 46.75183412720041, 45.42946527196829, 45.22045349996502, 46.81786731841227, 43.35597864325514, 50.11399256739039, 499.676370866798, 67.51169397876981, 56.96176307729663, 273.1455399157701, 111.96650096407846, 168.7521421608396, 1858.8635590350216, 91.70695977637291, 317.73208166279517, 102.52551596472793, 1001.4074386078951, 548.2220383830642, 97.18905051527798, 1732.907757417435, 397.5220260714337, 460.98376774913584, 290.3564043435723, 134.8547244144206, 325.1370344023712, 310.5856178790484, 858.9883332346272, 290.94418640473134, 592.1958952309122, 211.87234473821655, 296.92569792879283, 269.0051615305224, 189.69235049271364, 308.71953184626074, 188.50541115443656, 209.00866853401146, 378.18025457660383, 321.01412554570305, 248.0147220469879, 298.4719514318998, 240.21420211658287, 206.13101420414498, 207.73973754010922, 81.29923282855098, 114.38679030030978, 58.96601297661034, 49.15352165871943, 41.745008228256886, 40.01347581284715, 39.21215532905197, 33.99480355553714, 33.42252167648908, 27.32019935323356, 26.937516620175348, 26.76751158523685, 26.11999254616263, 25.65025044227616, 24.97996513588572, 27.285103705793833, 23.499601282881464, 22.658385827142194, 22.028563710176307, 21.254245296733494, 22.827500967762123, 20.54429981901072, 19.34181309799961, 18.963723064907423, 18.93811453618585, 22.927561248463523, 17.648831421031645, 17.59413579252528, 17.66974511152108, 17.708407380253437, 58.78922220399198, 18.642461823879437, 118.73243306263612, 64.47909846864265, 32.74932719051894, 73.1999266062669, 62.83508563326022, 76.2510525478029, 44.03701909596151, 28.085203226407863, 70.74941123758776, 38.23863442459834, 125.93750585104557, 78.87179836000783, 191.43757842777848, 183.3314911638268, 340.4847803618296, 75.27021995229907, 456.1876468751015, 75.24626559388734, 114.33219446206341, 117.26531431214123, 361.6661623327218, 174.72604874283348, 82.5097520784904, 100.5875019950449, 60.93380176757269, 85.10786780773392, 90.9890877869198, 90.43210316772789, 89.19192390451099, 79.99756398112646, 65.2131133570769, 77.07613720151429, 66.72052858856199, 64.700055236333, 112.49493729554676, 86.7257646409413, 66.43443515398758, 58.9471870473859, 55.77019976986071, 50.6580899178283, 40.94833742472876, 40.793705563596404, 40.01409964416813, 35.25312221338388, 34.93059721223284, 33.74078091426294, 32.79267148393809, 29.1587678825297, 26.317070815826504, 27.67868251257374, 77.4158942281575, 27.296210861494053, 25.56920875411509, 24.618518392250387, 24.68580092287999, 24.162969116251002, 23.278582862784678, 23.15318708089335, 22.470655277415585, 21.89695237286255, 21.74615418949133, 21.142273359998054, 19.326584592664773, 19.203838323310812, 20.428342889824254, 29.648769965647823, 52.32050244174678, 27.41678311322676, 29.03996273449965, 73.90945298269891, 88.7608005846962, 38.99439165243667, 31.341536439066846, 24.75872309753865, 37.8248123493932, 32.79872700916572, 27.773340444109223, 27.68342088673515, 20.761610185496806, 20.599112378690013, 19.373188858033945, 18.162900150970767, 17.929111548663673, 17.641111698966704, 17.67766820067775, 17.22442375109828, 25.603618822640126, 16.30929790095118, 15.193865114769093, 14.061069675423386, 14.152767626841978, 14.2493491404283, 13.643300985248692, 13.425283131897338, 13.184409039230944, 12.868999677279941, 12.760979371424968, 13.894405056543874, 12.249753434143928, 12.532305758432269, 12.115971691880349, 11.904582091758716, 12.222456265164977, 11.75695516427427, 14.099740477571443, 12.598688276244323, 15.130441718822649, 20.343571871461922, 52.445035850112276, 20.302407048607087, 52.81502719226093, 37.946992401639264, 25.726816704958413, 25.982132525636345, 54.165164178442005, 25.222339228211432, 31.966546445875718, 49.371494605700136, 28.35172406780037, 21.71036487160637, 45.765581049338635, 29.289057936565296, 55.089601039227745, 48.314330906003825, 26.7790328068202, 29.08690070678974, 81.39735830081813, 27.285031411511767, 21.765875930688924, 23.1614737465639, 29.737936726475155, 23.42162482180128, 26.74036874526865, 26.091386360651697, 23.708882082449975, 25.746649786741045, 25.101754450471507, 33.63838512218172, 34.360009467176205, 32.716456585557744, 32.32481164250036, 27.711655999576543, 24.81536701453095, 22.67810075905958, 22.824100447052736, 24.099611084296704, 22.211063923718037, 20.002244223818497, 19.222392184880295, 18.864807929395905, 18.762431344231615, 21.15179098493371, 16.624073066715916, 15.80672538197534, 15.786312081009196, 14.814240087709688, 14.437463592945404, 13.90834809703294, 13.78302364121938, 13.717237498399204, 13.602091766579045, 13.416854397617566, 13.288670847051272, 13.0666928104909, 13.319329317796582, 12.626445182601817, 12.2797089238805, 18.952974746230336, 41.787839410577135, 26.611880020947137, 17.553755537644037, 36.52103827640928, 197.40270253946153, 17.577441052813548, 42.03573804446299, 24.685809288076424, 17.57893367553727, 31.530634277344003, 32.37863850686509, 35.1269556159574, 50.596370410966145, 21.105211526129466, 19.379044384208836, 29.987343271534158, 21.61782631857675, 23.52698130256685, 30.572830794300902, 35.11045780143943, 20.46336449527967, 20.94979579620561, 21.013408487743565], \"Total\": [629.0, 2221.0, 1202.0, 2281.0, 565.0, 512.0, 456.0, 482.0, 243.0, 475.0, 113.0, 531.0, 87.0, 382.0, 115.0, 79.0, 209.0, 145.0, 354.0, 133.0, 323.0, 258.0, 112.0, 67.0, 796.0, 85.0, 132.0, 292.0, 308.0, 177.0, 456.56991207060173, 226.54505321476597, 185.68928610277993, 169.7249763016862, 475.5858388702305, 145.46647788847025, 117.27501639937374, 93.61732144569697, 88.32427606439957, 85.74633553200799, 78.51649584437767, 75.41521704441482, 69.20699975452067, 64.53478927944586, 62.06201114949981, 61.38900855719503, 59.45445939992379, 57.84859738796889, 56.41204578447636, 56.62882878463461, 59.6307691578891, 54.95767495028708, 50.76207542921915, 48.48748826111311, 47.434424792743144, 47.378365889209604, 46.04761158730674, 45.84499255383169, 47.47883821874899, 43.971634454169646, 50.83077012123935, 531.0186082674813, 69.00973279396509, 58.09445225061193, 294.71948159150384, 116.76084680558357, 179.9166335322751, 2221.5308371053034, 95.69081382836075, 354.05242879064497, 107.81080380000701, 1228.101483982286, 645.0956879291626, 102.06462373254514, 2281.0975951863575, 472.57822859799506, 565.1476806573193, 340.30191819178594, 146.87227459077977, 390.2727077514369, 378.2715088331045, 1202.351196844257, 353.9857304689287, 796.7046570542004, 254.26037006882206, 382.41537592200245, 344.1746312126565, 225.54335344977395, 415.2963510063415, 227.40758939713228, 263.3142681857679, 629.7598689790511, 512.8878487244573, 354.05194175992796, 482.61455274690275, 356.20601174767637, 270.2335517563419, 308.9974511853351, 81.94471459600541, 115.3568572458813, 59.676418177452526, 49.796150708895944, 42.39935937807521, 40.65735675467599, 39.8564677629076, 34.65632037526512, 34.11421407402876, 27.969735337542705, 27.58120685720283, 27.415479380281088, 26.772995791526856, 26.293704936552015, 25.628988516090956, 28.013254907847923, 24.152587852185324, 23.306152564539513, 22.694459771125025, 21.900978676294812, 23.528592637246348, 21.193118097636805, 19.98999879687122, 19.60870569879948, 19.584895905594635, 23.7154021046874, 18.291006217267082, 18.23719043269806, 18.320811069965416, 18.371087640375208, 61.89878674093239, 19.35074201486274, 132.10453075622237, 70.31254122299994, 35.122185735229294, 91.0935949290114, 80.64828538741779, 103.82634609097639, 54.98067432497613, 31.593967366504607, 109.34103254167626, 47.85169352040604, 258.6971006525355, 139.60232543136945, 512.8878487244573, 482.61455274690275, 1202.351196844257, 133.9263527228913, 2281.0975951863575, 139.5502262922783, 292.6481988820637, 323.7709200798988, 2221.5308371053034, 796.7046570542004, 203.24534816602065, 308.9974511853351, 116.96520038442429, 260.0383339705242, 309.2479766858441, 356.20601174767637, 415.2963510063415, 645.0956879291626, 230.1183037061862, 1228.101483982286, 378.2715088331045, 390.2727077514369, 113.18772853640685, 87.41849900116289, 67.21468412468408, 59.63978548178872, 56.463749315660344, 51.35041058477439, 41.640656239700895, 41.487472661289104, 40.74056475641244, 35.94555406170363, 35.62329984722004, 34.435114520831, 33.488416991758605, 29.856950458381483, 27.00952204123408, 28.41570459344815, 79.48700103065704, 28.03036529874063, 26.261996607057895, 25.31099180311907, 25.381127159961974, 24.8574477007992, 23.971005293820344, 23.85944886837947, 23.164479568716214, 22.58937063087577, 22.44127542402332, 21.839781276337924, 20.01893421689188, 19.902245271674456, 21.25587827766229, 33.92642340725009, 91.9879183900244, 34.956043446637, 40.276441365212705, 565.1476806573193, 1228.101483982286, 209.1801954107746, 139.86287074054815, 629.7598689790511, 38.516790330612096, 33.47993426385961, 28.44441373234948, 28.37052849669966, 21.460545895327552, 21.31082040288244, 20.046475885015035, 18.850841679631042, 18.611560924743024, 18.315586184798534, 18.35565241670651, 17.91404946678832, 26.630101136341615, 17.01355108860046, 15.867673857731209, 14.727479758416711, 14.841843869704336, 14.94377998624599, 14.31309350638562, 14.103842208824734, 13.856479412147726, 13.54815109461075, 13.435865290054899, 14.639160375978562, 12.923170180450127, 13.222907090160287, 12.799456721015043, 12.577850184203028, 12.915857045767414, 12.442103895071767, 15.042765189943273, 13.393158575189089, 16.45220765129668, 23.303994649327304, 72.30332713916451, 24.177314180784144, 85.73567027044456, 59.34116597028662, 36.17314207378943, 40.52666437727108, 145.9512238997346, 41.10224746007565, 74.68064625906088, 177.38632895968416, 66.78226778696742, 37.602458289668945, 191.15573757544018, 75.65185810338643, 382.41537592200245, 354.05194175992796, 68.46680898093919, 89.584343058163, 2281.0975951863575, 87.36564688437268, 40.652362148691104, 56.209815293118886, 565.1476806573193, 92.64885186793768, 531.0186082674813, 629.7598689790511, 206.6704431008944, 1228.101483982286, 796.7046570542004, 34.323388669259465, 35.068539945315415, 33.39748070670235, 33.02175197595565, 28.408163128947418, 25.496963482781783, 23.36464803085829, 23.516017645571967, 24.844594921758098, 22.90130088395755, 20.68403712823987, 19.903174116237086, 19.543596860777388, 19.448869848905083, 21.95752103641533, 17.30633631835436, 16.489518570219687, 16.468836644260406, 15.509650079117296, 15.115520476876332, 14.589591990957375, 14.462133176163562, 14.402084729625878, 14.28784778398791, 14.093554040557631, 13.972885876423053, 13.745908544857693, 14.021966843870683, 13.302179490205404, 12.974554466103259, 20.23625745515561, 50.80362344133627, 31.527943144543876, 19.796340662573446, 52.83796644529268, 629.7598689790511, 21.95265080973374, 112.27457559329173, 44.18655507287112, 23.09048525074852, 76.59715223209932, 85.73567027044456, 104.02410040376107, 243.61094679769343, 37.61540856461971, 30.237591789766114, 133.5828944561855, 49.527646499937575, 74.32489652212135, 292.6481988820637, 1228.101483982286, 44.47300749836158, 72.85759051659691, 309.2479766858441], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.7697, -5.4719, -5.6713, -5.7615, -4.7318, -5.9164, -6.1328, -6.3595, -6.4181, -6.448, -6.5368, -6.5775, -6.6643, -6.7345, -6.7741, -6.785, -6.8175, -6.845, -6.8703, -6.8668, -6.8153, -6.897, -6.9772, -7.0236, -7.0459, -7.0472, -7.0759, -7.0805, -7.0458, -7.1226, -6.9777, -4.6781, -6.6797, -6.8497, -5.282, -6.1738, -5.7636, -3.3643, -6.3734, -5.1308, -6.2619, -3.9829, -4.5854, -6.3154, -3.4345, -4.9068, -4.7587, -5.2209, -5.9878, -5.1078, -5.1536, -4.1363, -5.2189, -4.5082, -5.5361, -5.1986, -5.2973, -5.6466, -5.1596, -5.6529, -5.5497, -4.9567, -5.1206, -5.3786, -5.1934, -5.4105, -5.5635, -5.5558, -5.5138, -5.1723, -5.835, -6.017, -6.1803, -6.2227, -6.2429, -6.3857, -6.4027, -6.6043, -6.6184, -6.6247, -6.6492, -6.6674, -6.6938, -6.6056, -6.7549, -6.7914, -6.8196, -6.8554, -6.7839, -6.8893, -6.9496, -6.9694, -6.9707, -6.7796, -7.0412, -7.0443, -7.0401, -7.0379, -5.838, -6.9865, -5.135, -5.7456, -6.423, -5.6187, -5.7714, -5.5779, -6.1269, -6.5767, -5.6528, -6.2681, -5.0761, -5.5441, -4.6574, -4.7006, -4.0815, -5.5908, -3.789, -5.5911, -5.1728, -5.1475, -4.0212, -4.7487, -5.499, -5.3009, -5.8021, -5.468, -5.4012, -5.4073, -5.4211, -5.5299, -5.7343, -5.5671, -5.7114, -5.7422, -4.4691, -4.7293, -4.9958, -5.1154, -5.1708, -5.2669, -5.4797, -5.4835, -5.5028, -5.6295, -5.6387, -5.6733, -5.7018, -5.8193, -5.9218, -5.8714, -4.8428, -5.8853, -5.9506, -5.9885, -5.9858, -6.0072, -6.0445, -6.0499, -6.0798, -6.1057, -6.1126, -6.1407, -6.2305, -6.2369, -6.1751, -5.8026, -5.2346, -5.8809, -5.8233, -4.8892, -4.7061, -5.5286, -5.7471, -5.9828, -5.5418, -5.6843, -5.8507, -5.8539, -6.1416, -6.1495, -6.2108, -6.2754, -6.2883, -6.3045, -6.3024, -6.3284, -5.932, -6.383, -6.4538, -6.5313, -6.5248, -6.518, -6.5615, -6.5776, -6.5957, -6.6199, -6.6283, -6.5432, -6.6692, -6.6464, -6.6802, -6.6978, -6.6715, -6.7103, -6.5286, -6.6411, -6.458, -6.162, -5.215, -6.164, -5.2079, -5.5385, -5.9272, -5.9173, -5.1827, -5.947, -5.71, -5.2754, -5.83, -6.0969, -5.3512, -5.7975, -5.1658, -5.297, -5.8871, -5.8044, -4.7754, -5.8684, -6.0944, -6.0322, -5.7823, -6.0211, -5.8886, -5.9131, -6.0089, -5.9264, -5.9518, -5.505, -5.4837, -5.5327, -5.5448, -5.6988, -5.8092, -5.8992, -5.8928, -5.8384, -5.92, -6.0248, -6.0646, -6.0833, -6.0888, -5.9689, -6.2098, -6.2602, -6.2615, -6.325, -6.3508, -6.3881, -6.3972, -6.402, -6.4104, -6.4241, -6.4337, -6.4506, -6.4314, -6.4848, -6.5127, -6.0787, -5.288, -5.7393, -6.1554, -5.4227, -3.7354, -6.154, -5.2821, -5.8144, -6.1539, -5.5697, -5.5431, -5.4617, -5.0967, -5.9711, -6.0564, -5.6199, -5.9471, -5.8625, -5.6005, -5.4621, -6.002, -5.9785, -5.9755], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.636, 0.6346, 0.6339, 0.6336, 0.633, 0.633, 0.632, 0.6306, 0.6302, 0.63, 0.6293, 0.6288, 0.6279, 0.6276, 0.6271, 0.6271, 0.6266, 0.6265, 0.6263, 0.6261, 0.6259, 0.6258, 0.625, 0.6245, 0.6241, 0.624, 0.6238, 0.6236, 0.6233, 0.6232, 0.6231, 0.5765, 0.6154, 0.6176, 0.5613, 0.5954, 0.5733, 0.4591, 0.5948, 0.5291, 0.587, 0.4333, 0.4746, 0.5884, 0.3625, 0.4644, 0.4336, 0.4786, 0.5519, 0.4547, 0.4402, 0.301, 0.4412, 0.3407, 0.4549, 0.3843, 0.3909, 0.4642, 0.3408, 0.4497, 0.4063, 0.1273, 0.1687, 0.2814, 0.1568, 0.2433, 0.3665, 0.2403, 1.6095, 1.609, 1.6055, 1.6045, 1.6019, 1.6015, 1.6011, 1.5982, 1.597, 1.594, 1.5938, 1.5935, 1.5928, 1.5927, 1.5918, 1.5911, 1.59, 1.5893, 1.5877, 1.5875, 1.5872, 1.5864, 1.5845, 1.584, 1.5839, 1.5837, 1.5817, 1.5815, 1.5813, 1.5807, 1.5659, 1.5802, 1.5107, 1.5308, 1.5475, 1.3988, 1.3679, 1.3088, 1.3955, 1.4997, 1.1821, 1.3932, 0.8976, 1.0465, 0.632, 0.6495, 0.3558, 1.0412, 0.0079, 0.9998, 0.6776, 0.6018, -0.1978, 0.1002, 0.7159, 0.4951, 0.9654, 0.5005, 0.394, 0.2465, 0.0792, -0.47, 0.3565, -1.151, -0.1177, -0.1796, 2.3312, 2.3294, 2.3257, 2.3257, 2.325, 2.3238, 2.3206, 2.3205, 2.3193, 2.3179, 2.3177, 2.317, 2.3163, 2.3137, 2.3114, 2.3111, 2.3109, 2.3108, 2.3106, 2.3096, 2.3096, 2.309, 2.308, 2.3073, 2.3069, 2.3062, 2.3059, 2.3049, 2.3021, 2.3016, 2.2976, 2.2026, 1.7731, 2.0944, 2.0102, 0.3031, -0.2899, 0.6576, 0.8416, -0.8988, 2.3365, 2.3341, 2.3307, 2.3301, 2.3215, 2.3207, 2.3205, 2.3174, 2.3173, 2.3171, 2.317, 2.3154, 2.3153, 2.3123, 2.3112, 2.3083, 2.3071, 2.307, 2.3067, 2.3053, 2.3049, 2.3032, 2.3031, 2.3024, 2.3011, 2.301, 2.2997, 2.2996, 2.2994, 2.298, 2.2899, 2.2935, 2.2709, 2.2188, 2.0335, 2.1799, 1.8702, 1.9075, 2.0138, 1.9101, 1.3634, 1.8663, 1.5061, 1.0757, 1.4979, 1.8053, 0.9251, 1.4057, 0.4171, 0.3629, 1.4159, 1.2297, -0.9784, 1.1909, 1.7299, 1.468, -0.59, 0.9795, -0.634, -0.8291, 0.1893, -1.5103, -1.1029, 2.4886, 2.4883, 2.4881, 2.4874, 2.4839, 2.4816, 2.4789, 2.4789, 2.4783, 2.4781, 2.4752, 2.4739, 2.4734, 2.4728, 2.4713, 2.4685, 2.4664, 2.4664, 2.4629, 2.4628, 2.4609, 2.4606, 2.46, 2.4595, 2.4595, 2.4585, 2.4581, 2.4573, 2.4566, 2.4537, 2.4432, 2.3134, 2.3392, 2.3885, 2.1394, 1.3486, 2.2865, 1.5263, 1.9265, 2.236, 1.6211, 1.535, 1.4231, 0.937, 1.9308, 2.0638, 1.0148, 1.6797, 1.3584, 0.2499, -1.046, 1.7325, 1.2624, -0.1802]}, \"token.table\": {\"Topic\": [2, 1, 2, 5, 2, 1, 2, 4, 5, 1, 2, 5, 1, 1, 2, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 5, 1, 2, 4, 5, 1, 1, 2, 4, 5, 5, 3, 2, 5, 4, 3, 1, 4, 1, 3, 1, 2, 4, 5, 1, 5, 2, 3, 4, 3, 3, 5, 2, 5, 1, 2, 2, 4, 1, 3, 5, 4, 2, 4, 1, 2, 1, 3, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 5, 1, 1, 2, 4, 2, 3, 3, 2, 3, 1, 4, 5, 5, 4, 3, 4, 4, 4, 5, 3, 5, 1, 4, 1, 2, 4, 3, 5, 5, 1, 3, 4, 1, 2, 1, 4, 2, 5, 2, 4, 2, 1, 2, 1, 2, 4, 1, 2, 4, 3, 1, 3, 4, 4, 1, 2, 5, 3, 1, 2, 4, 1, 5, 1, 2, 4, 5, 5, 1, 2, 1, 5, 1, 2, 3, 1, 2, 4, 1, 2, 3, 4, 5, 3, 1, 2, 1, 1, 2, 4, 1, 4, 4, 4, 1, 2, 4, 4, 2, 4, 2, 1, 2, 4, 5, 1, 4, 5, 1, 2, 4, 3, 1, 2, 1, 4, 2, 1, 1, 2, 5, 1, 4, 1, 4, 1, 5, 1, 2, 5, 1, 4, 5, 1, 3, 5, 5, 3, 3, 4, 5, 1, 1, 2, 5, 1, 4, 4, 3, 4, 5, 2, 2, 1, 2, 4, 5, 1, 4, 3, 2, 5, 5, 1, 2, 1, 4, 5, 5, 4, 2, 4, 3, 1, 1, 2, 3, 5, 5, 2, 5, 2, 3, 1, 3, 5, 2, 1, 2, 2, 1, 2, 4, 5, 2, 4, 1, 2, 4, 2, 1, 1, 2, 4, 5, 3, 5, 4, 1, 3, 1, 2, 4, 1, 2, 3, 4, 2, 5, 5, 1, 2, 4, 5, 3, 1, 2, 4, 1, 4, 1, 2, 3, 1, 2, 5, 5, 1, 2, 4, 5, 2, 4, 1, 1, 2, 1, 2, 4, 2, 5, 4, 1, 2, 3, 4, 1, 2, 4, 5, 1, 2, 4, 5, 1, 4, 5, 1, 2, 4, 1, 2, 5, 2, 2, 2, 1, 2, 4, 5, 1, 2, 1, 2, 2, 4, 4, 1, 2, 4, 5, 4, 4, 1, 2, 4, 5, 3, 1, 4, 1, 2, 3, 1, 2, 4, 1, 1, 3, 3, 4, 1, 4, 3, 4, 4, 4, 5, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 5, 3, 3, 3, 2, 4, 1, 2, 4, 5, 2, 2, 1, 2, 4, 5, 1, 2, 4, 1, 4, 5, 5, 5, 1, 2, 4, 5, 1, 4, 1, 5, 1, 2, 4, 5, 2, 1, 1, 2, 4, 5], \"Freq\": [0.9840118021661921, 0.7623035654201127, 0.2331316729197432, 0.003700502744757829, 0.9869941352220135, 0.7766424121517964, 0.033994449016745296, 0.14382266891699935, 0.04706923710010887, 0.8368103512001266, 0.16295069775925003, 0.00045014004905870173, 0.9923561763993707, 0.7144335217984301, 0.28277927521707363, 0.0008317037506384518, 0.0008317037506384518, 0.5186419976079977, 0.09019860827965177, 0.11274826034956471, 0.27623323785643356, 0.9934218174305514, 0.9840902018286798, 0.93037330405277, 0.842410104726544, 0.133012121798928, 0.0266024243597856, 0.842188606912241, 0.10157048525574765, 0.03174077664242114, 0.025392621313936912, 0.9917131630022044, 0.8337909676707258, 0.07865952525195527, 0.08259250151455304, 0.003932976262597763, 0.9822991814836353, 0.9818224229133722, 0.9848450806014384, 0.9690582142128732, 0.9290904937611133, 0.9819282922994799, 0.9957285231821299, 0.9806243652564041, 0.985330718007255, 0.9739093824035008, 0.2793649738963193, 0.5658931522515186, 0.09312165796543977, 0.06446884012991984, 0.7710568064819368, 0.22457965237337962, 0.9673387148356728, 0.9736948257890111, 0.9381892480281199, 0.9655054005897946, 0.772398628043174, 0.2002514961593414, 0.9810620294319086, 0.9457359590001975, 0.7126769029611583, 0.28246340666143466, 0.3649435475412904, 0.6082392459021506, 0.47090546556742174, 0.2152710699736785, 0.32290660496051776, 0.9477975135870497, 0.9638294474818755, 0.9285647277285973, 0.9263045609532927, 0.07125419699640713, 0.9908415713979606, 0.989506560898739, 0.9008018068630465, 0.0529883415801792, 0.03784881541441371, 0.7597219880714574, 0.1999037660476541, 0.004383854518588906, 0.035509221600570136, 0.8221607832939248, 0.1771214549218423, 0.0026436038048036166, 0.984987307497272, 0.9653291199991776, 0.9224075036423983, 0.993663221375654, 0.7440469901823953, 0.2143047965250265, 0.040934624055342136, 0.8862451389908419, 0.09495483632044735, 0.9846146459361012, 0.9102216885750242, 0.07111106941992376, 0.5433108936520858, 0.08016062365358644, 0.3740829103834034, 0.9606441184924602, 0.9843760628525785, 0.9803364374044918, 0.9671408041906905, 0.9831423537471452, 0.7191923533465334, 0.2627818214150795, 0.9409161898060883, 0.956392115720744, 0.6867687945973688, 0.309045957568816, 0.7937283514486604, 0.14431424571793824, 0.06076389293386874, 0.33071416763369665, 0.6283569185040236, 0.984393172523862, 0.9912960066762341, 0.12408326158843426, 0.827221743922895, 0.2600496022111924, 0.7319914728907638, 0.9853682552723435, 0.014490709636357992, 0.9504752948246215, 0.9248872499900219, 0.9818744927407257, 0.9217346456035886, 0.9754579266483322, 0.8327510316375779, 0.16655020632751558, 0.49414314747843824, 0.07487017386036943, 0.4192729736180688, 0.6229850711870927, 0.3268748830302647, 0.04614704231015501, 0.9882501239526227, 0.8157159903121503, 0.13093922621062715, 0.053083470085389384, 0.9781253782597077, 0.7799321110056084, 0.012314717542193817, 0.2093501982172949, 0.9877131719871701, 0.941586588898111, 0.007532692711184888, 0.050845675800497994, 0.9963285737642148, 0.9780567588717926, 0.6737674044929018, 0.25266277668483816, 0.036495734410032184, 0.03368837022464509, 0.9695299562804253, 0.9811608129827852, 0.017213347596189216, 0.992013952315401, 0.9671398080216197, 0.4586162394746421, 0.5374409056343462, 0.9853706040587148, 0.167183215711863, 0.7941202746313493, 0.020897901963982876, 0.815079220288963, 0.06269840156068945, 0.072469581024693, 0.02117088883867436, 0.028499273436677026, 0.971298125052121, 0.9393239339912572, 0.05558129786930516, 0.977249382732469, 0.40918120581007533, 0.1779048720913371, 0.40918120581007533, 0.959225657094533, 0.0342580591819476, 0.9595405239591108, 0.964467111125243, 0.2912048241968882, 0.5600092773017081, 0.14186901691643272, 0.9856650177363794, 0.9588612595988684, 0.9548645257282913, 0.9789274319933884, 0.4783900961455073, 0.38954622114705595, 0.023919504807275366, 0.10592923557507662, 0.9967932275858916, 0.4253576023908796, 0.5582818531380295, 0.4831905718490892, 0.48705609642388187, 0.027058672023548995, 0.9639786789242025, 0.056944064218472056, 0.9395770596047889, 0.9944942538033102, 0.9375397926302264, 0.9908876977541903, 0.9926957836974998, 0.407363732481859, 0.022631318471214388, 0.5657829617803597, 0.9828879030854872, 0.9368446278575682, 0.9503782647960696, 0.03919085628025029, 0.9966655044355448, 0.0042053396811626365, 0.6174699836626766, 0.3791845872827846, 0.002072046925042539, 0.9815684874888029, 0.9854149020541508, 0.9703133497721538, 0.9836561571021287, 0.8842665093187804, 0.11790220124250404, 0.980508914988352, 0.99317608991274, 0.9952126951852912, 0.1822103414602856, 0.8199465365712852, 0.9894220858325848, 0.6731447110715573, 0.32686353758763115, 0.9720814911747625, 0.5623947047044228, 0.42849120358432213, 0.9506039206741426, 0.06078211636972532, 0.9117317455458798, 0.9856321886390639, 0.9868638736620421, 0.9693995901145613, 0.7004621942397407, 0.16099332690187587, 0.13557332791736915, 0.0028244443316118575, 0.608048515307265, 0.38333493356327575, 0.9497299490255394, 0.9884713175137294, 0.9880984823318549, 0.9721854239703261, 0.9553773496677455, 0.04637754124600706, 0.9962879597566097, 0.12687158124021888, 0.8563831733714774, 0.9680452966008328, 0.9869396688629624, 0.9701353579608482, 0.9675595668276369, 0.9849838363142835, 0.9779031535618183, 0.04965682002202475, 0.22345569009911137, 0.7200238903193589, 0.926200326440439, 0.9798536638729806, 0.04941625210175556, 0.9389087899333557, 0.9838317882138173, 0.982503028919465, 0.26496099191280015, 0.03785157027325717, 0.7002540500552575, 0.9775340308111088, 0.6258678204178967, 0.37240110186859277, 0.9698338614909676, 0.32380325708474195, 0.22666227995931937, 0.24824916376496883, 0.19428195425084518, 0.9882377408827185, 0.9432790240151538, 0.898172061935033, 0.09885541562178035, 0.0028244404463365815, 0.9711277812335258, 0.9825743183067086, 0.7430608002078314, 0.21965479735873392, 0.031379256765533416, 0.0062758513531066835, 0.9687118522725767, 0.02516134681227472, 0.986582725970254, 0.9888956067407626, 0.9873642203057642, 0.9976549446948088, 0.8013735768896637, 0.18662124393320936, 0.2174198563250551, 0.20654886350880233, 0.5652916264451433, 0.9540581120191135, 0.10102877264489385, 0.9092589538040446, 0.9905781835128331, 0.4614315318632116, 0.105744726051986, 0.08651841222435218, 0.3364604919835918, 0.9491014753406749, 0.10637602385424297, 0.31912807156272893, 0.5850681311983363, 0.4427786984225602, 0.5411739647386847, 0.5904194171370564, 0.408373430186464, 0.9546661565387016, 0.34753650223227933, 0.6493445173287324, 0.9769205176243002, 0.9595881782490693, 0.5074396470140932, 0.2197161358205352, 0.24064148208915762, 0.0313880194029336, 0.27644819959518707, 0.7187653189474864, 0.9970089766171789, 0.8521844412189384, 0.14398978489561373, 0.2921123431583893, 0.32132357747422824, 0.3943516632638256, 0.9785111975300362, 0.9715318905404408, 0.970644820414699, 0.5505392502835039, 0.09294818511279937, 0.22164567219206005, 0.12869748707926068, 0.3590811614220339, 0.5215226392081921, 0.04274775731214689, 0.0769459631618644, 0.11749784081696446, 0.3524935224508934, 0.11749784081696446, 0.41777010068254034, 0.4845778407829302, 0.060572230097866275, 0.44419635405101937, 0.23980614252364377, 0.39054143210993414, 0.36998661989362186, 0.637029228489105, 0.294262232449282, 0.06790666902675739, 0.9824892539560466, 0.9798004534277194, 0.9522789086105721, 0.8220670353421003, 0.1412486315020791, 0.03672464419054056, 0.9772834601707259, 0.2000702998835905, 0.800281199534362, 0.048466216511739185, 0.9531689247308707, 0.34545157404693144, 0.6415529232300156, 0.9827695285526563, 0.6139465683673209, 0.06697598927643501, 0.3237172815027692, 0.9271167265441504, 0.9785398797601033, 0.9306799530022309, 0.8311068267380498, 0.09674259358855607, 0.03957651555895476, 0.03517912494129311, 0.990023736162258, 0.03755149088169696, 0.9763387629241209, 0.8031353048030786, 0.009561134580989032, 0.1864421243292861, 0.6300751159173212, 0.36136661059964015, 0.006177207018797267, 0.9934059057003136, 0.9987517528958115, 0.9632411034333925, 0.08582219615544463, 0.8582219615544463, 0.989946102002894, 0.9489758321543703, 0.9626234762802209, 0.9563390003550093, 0.9453181439503527, 0.6181791059989014, 0.3732402149427329, 0.9669292254699179, 0.9594925084735322, 0.9191659921938387, 0.05446909583370896, 0.00680863697921362, 0.02042591093764086, 0.6002287834135936, 0.004763720503282489, 0.03969767086068741, 0.04128557769511491, 0.3128176463822168, 0.985415345494569, 0.17715271845506136, 0.8267126861236197, 0.9892725053146932, 0.9615480912692209, 0.9917867778657815, 0.9886652349770534, 0.9404268348610909, 0.9614297999912416, 0.020900647825896554, 0.010450323912948277, 0.010450323912948277, 0.9888298382726687, 0.9689573749461319, 0.7815799759912925, 0.16561360086060845, 0.008716505308453075, 0.04648802831174974, 0.13639471623182392, 0.7811697384186279, 0.07439711794463122, 0.9899147022818283, 0.2165394077128767, 0.7795418677663561, 0.954621604023437, 0.966004882574341, 0.6580524914905523, 0.17419036539455798, 0.11612691026303865, 0.05322483387055938, 0.353885867536124, 0.6403649031606053, 0.5171676325431181, 0.44971098482010274, 0.8494863789264321, 0.12401261006225285, 0.017051733883559766, 0.009300945754668964, 0.990581004431833, 0.9975940626068349, 0.4529383934606322, 0.13725405862443402, 0.10980324689954721, 0.2882335231113114], \"Term\": [\"'d\", \"'m\", \"'m\", \"'m\", \"'re\", \"'s\", \"'s\", \"'s\", \"'s\", \",\", \",\", \",\", \"-\", \".\", \".\", \".\", \".\", \"abarth\", \"abarth\", \"abarth\", \"abarth\", \"ago\", \"all\", \"allah\", \"already\", \"already\", \"already\", \"also\", \"also\", \"also\", \"also\", \"although\", \"always\", \"always\", \"always\", \"always\", \"ana\", \"android\", \"answer\", \"app\", \"application\", \"auto\", \"automatic\", \"automatically\", \"available\", \"avon\", \"back\", \"back\", \"back\", \"back\", \"battery\", \"battery\", \"beam\", \"belle\", \"board\", \"bon\", \"bonne\", \"bonne\", \"book\", \"bosch\", \"bought\", \"bought\", \"box\", \"box\", \"bravo\", \"bravo\", \"bravo\", \"bro\", \"brother\", \"bulbs\", \"buy\", \"buy\", \"buying\", \"c'est\", \"ca\", \"ca\", \"ca\", \"car\", \"car\", \"car\", \"car\", \"cars\", \"cars\", \"cars\", \"certainly\", \"changes\", \"chi\", \"choice\", \"city\", \"city\", \"city\", \"cm\", \"cm\", \"coffre\", \"colour\", \"colour\", \"come\", \"come\", \"come\", \"comments\", \"compartment\", \"con\", \"conditioning\", \"confirm\", \"connect\", \"connect\", \"connected\", \"conso\", \"consumes\", \"consumes\", \"consumption\", \"consumption\", \"consumption\", \"content\", \"content\", \"continuation\", \"cost\", \"cross\", \"cross\", \"cute\", \"cute\", \"cylinder\", \"cylinder\", \"dad\", \"date\", \"device\", \"disinfected\", \"doors\", \"drive\", \"drive\", \"driver\", \"driver\", \"driver\", \"driving\", \"driving\", \"driving\", \"du\", \"e\", \"e\", \"e\", \"eh\", \"electric\", \"electric\", \"electric\", \"enfants\", \"engine\", \"engine\", \"engine\", \"engines\", \"episode\", \"even\", \"even\", \"even\", \"even\", \"evening\", \"everyone\", \"everyone\", \"example\", \"exit\", \"expensive\", \"expensive\", \"explained\", \"feel\", \"feel\", \"feel\", \"fiat\", \"fiat\", \"fiat\", \"fiat\", \"fiat\", \"fiha\", \"first\", \"first\", \"friendly\", \"front\", \"front\", \"front\", \"full\", \"full\", \"function\", \"gasoline\", \"gear\", \"gear\", \"gear\", \"gears\", \"generally\", \"generation\", \"german\", \"get\", \"get\", \"get\", \"get\", \"girl\", \"gives\", \"gives\", \"go\", \"go\", \"go\", \"grand\", \"green\", \"green\", \"greetings\", \"hair\", \"head\", \"heard\", \"help\", \"help\", \"help\", \"hope\", \"hour\", \"hp\", \"hp\", \"hybrid\", \"hybrid\", \"i\", \"i\", \"i\", \"ideal\", \"info\", \"installed\", \"instead\", \"in\\u00e8s\", \"in\\u00e8s\", \"iphone\", \"j'ai\", \"je\", \"key\", \"key\", \"kilometres\", \"know\", \"know\", \"kwh\", \"led\", \"led\", \"lenticular\", \"li\", \"li\", \"licence\", \"likes\", \"link\", \"little\", \"little\", \"little\", \"little\", \"live\", \"live\", \"lo\", \"looks\", \"luck\", \"mafia\", \"manual\", \"manual\", \"many\", \"map\", \"map\", \"maps\", \"matter\", \"max\", \"metres\", \"mi\", \"mild\", \"million\", \"million\", \"million\", \"minute\", \"minutes\", \"missing\", \"missing\", \"mobile\", \"moi\", \"motor\", \"motor\", \"motor\", \"moves\", \"much\", \"much\", \"music\", \"must\", \"must\", \"must\", \"must\", \"n't\", \"nav\", \"new\", \"new\", \"new\", \"nice\", \"often\", \"one\", \"one\", \"one\", \"one\", \"pa\", \"pa\", \"passenger\", \"performance\", \"petite\", \"petrol\", \"phone\", \"phone\", \"place\", \"place\", \"place\", \"placed\", \"plate\", \"plate\", \"play\", \"please\", \"please\", \"please\", \"please\", \"por\", \"position\", \"position\", \"position\", \"pretty\", \"pretty\", \"price\", \"price\", \"prix\", \"problem\", \"problem\", \"protection\", \"pull\", \"put\", \"put\", \"put\", \"put\", \"radio\", \"radio\", \"range\", \"really\", \"really\", \"rear\", \"rear\", \"rear\", \"red\", \"regards\", \"removed\", \"review\", \"review\", \"review\", \"review\", \"right\", \"right\", \"right\", \"right\", \"roof\", \"roof\", \"roof\", \"roof\", \"says\", \"says\", \"says\", \"seat\", \"seat\", \"seat\", \"see\", \"see\", \"see\", \"shift\", \"shifting\", \"shopping\", \"small\", \"small\", \"small\", \"socialism\", \"someone\", \"someone\", \"sometimes\", \"sometimes\", \"soon\", \"soon\", \"sounds\", \"start\", \"start\", \"start\", \"starts\", \"stellantis\", \"stick\", \"still\", \"still\", \"still\", \"still\", \"suis\", \"suitcase\", \"suitcase\", \"test\", \"test\", \"test\", \"think\", \"think\", \"think\", \"thousand\", \"times\", \"tiphaine\", \"tipo\", \"tipo\", \"transmission\", \"transport\", \"trop\", \"turbocharged\", \"twice\", \"uconnect\", \"uconnect\", \"update\", \"vacances\", \"version\", \"version\", \"version\", \"version\", \"video\", \"video\", \"video\", \"video\", \"video\", \"vid\\u00e9o\", \"voice\", \"voice\", \"voiture\", \"voitures\", \"vous\", \"w\", \"wagon\", \"wanted\", \"wanted\", \"wanted\", \"wanted\", \"water\", \"we\", \"well\", \"well\", \"well\", \"well\", \"wheel\", \"wheel\", \"wheel\", \"whole\", \"windscreen\", \"windscreen\", \"wiper\", \"wipers\", \"without\", \"without\", \"without\", \"without\", \"women\", \"women\", \"works\", \"works\", \"would\", \"would\", \"would\", \"would\", \"xd\", \"years\", \"yes\", \"yes\", \"yes\", \"yes\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 4, 1, 5, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el242476394413456135561814\", ldavis_el242476394413456135561814_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el242476394413456135561814\", ldavis_el242476394413456135561814_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el242476394413456135561814\", ldavis_el242476394413456135561814_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic visualization saved to fiat_topic.html.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Download stopwords if not already available\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the translated dataset\n",
    "file_path = 'translated_comments_with_plain_texts.csv'  # Update with the correct path\n",
    "translated_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the dataset has no NaN values in the 'translated_plain_texts' column\n",
    "translated_data = translated_data.dropna(subset=['translated_plain_texts'])\n",
    "\n",
    "# Extract the comments\n",
    "comments = translated_data['translated_plain_texts'].tolist()\n",
    "\n",
    "# Define stopwords and unrelated words\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "unrelated_words = set([\n",
    "    'mp', 'amp', 'km', 'speed', 'lt', 'oh', 'ha', 'ho', 'eu', 'el', 'al', 'la', 'una', 'un', 'ce', 'oui', 'ne', \n",
    "    'que', 'qui', 'pour', 'par', 'le', 'la', 'de', 'des', 'en', 'pas', 'une', 'mais', 'au', 'bien', 'à', 'très', \n",
    "    'sont', 'il', 'dans', 'les', 'est', 'comme', 'et', 'se', 'au', 'avec', 'même', 'plus', 'nous', 'elle', \n",
    "    'fait', 'cette', 'ça', 'sur', 'vraiment', 'si', 'ou', 'plus', 'c', 'm', 'qu', 'j', 'n', 'd', 't', 'y', \n",
    "    'l', 's', 'tu', 'p', 'g', 'k', 'r', 'v', 'h', 'u', 'q', 'i', 'z', 'x', 'merci', 'thanks', 'thank', 'hello', \n",
    "    'congratulations', 'bonjour', 'good', 'great', 'nice', 'excellent', 'perfect', 'awesome', 'wonderful', \n",
    "    'fantastic', 'love', 'like', 'beautiful', 'amazing', 'best', 'awesome', 'super', 'cool', 'top', 'amazing', \n",
    "    'goodbye', 'bye', 'hey', 'hi', 'ciao', 'hola', 'salut', 'yo', 'keep up the good work', 'job well done', \n",
    "    'job done', 'proud', 'hurray', 'hurray for', 'thank you', 'many thanks', 'thanks a lot', 'thanks for sharing', \n",
    "    'thanks for', 'thanks very much', 'appreciate it', 'much appreciated', 'appreciated', 'appreciation', 'respect', \n",
    "    'respect for', 'big fan', 'fan of', 'support', 'supporting', 'great job', 'nice job', 'job', 'work', 'working', \n",
    "    'cool', 'cool stuff', 'cool work', 'nice stuff', 'nice one', 'awesome one', 'fantastic job', 'fantastic work', \n",
    "    'fantastic stuff', 'fantastic one', 'super job', 'super work', 'super stuff', 'super one', 'wow', 'wow amazing', \n",
    "    'wow fantastic', 'wow awesome', 'wow great', 'wow cool', 'impressive', 'impressive work', 'impressive job', \n",
    "    'impressive stuff', 'impressive one', 'fantabulous', 'fabulous', 'fabulous work', 'fabulous job', \n",
    "    'fabulous stuff', 'fabulous one', 'marvelous', 'marvelous work', 'marvelous job', 'marvelous stuff', \n",
    "    'marvelous one', 'remarkable', 'remarkable work', 'remarkable job', 'remarkable stuff', 'remarkable one', \n",
    "    'good going', 'good one', 'good job', 'good work', 'good stuff', 'good day', 'good morning', 'good night', \n",
    "    'good evening', 'good afternoon', 'nice going', 'nice one', 'nice day', 'nice morning', 'nice night', \n",
    "    'nice evening', 'nice afternoon', 'have a nice day', 'have a great day', 'have a good day', 'have a wonderful day', \n",
    "    'have a fantastic day', 'have a nice one', 'have a great one', 'have a good one', 'have a wonderful one', \n",
    "    'have a fantastic one', 'well done', 'good luck', 'best of luck', 'good fortune', 'bon voyage', 'happy journey', \n",
    "    'happy travels', 'safe travels', 'travel safe', 'travel safely', 'stay safe', 'stay healthy', 'take care', \n",
    "    'all the best', 'best of health', 'wish you well', 'wish you the best', 'wish you all the best', 'wish you success', \n",
    "    'wish you happiness', 'wish you joy', 'wish you love', 'wish you peace', 'wish you luck', 'wish you good luck', \n",
    "    'wish you good fortune', 'wish you prosperity', 'wish you wealth', 'wish you health', 'wish you success', \n",
    "    'wish you the best of luck', 'wish you the best of health', 'wish you the best of success', \n",
    "    'wish you the best of happiness', 'wish you the best of joy', 'wish you the best of love', 'wish you the best of peace', \n",
    "    'wish you the best of prosperity', 'wish you the best of wealth', 'wish you the best of health', \n",
    "    'wish you the best of success', 'wish you the best of happiness', 'wish you the best of joy', 'wish you the best of love', \n",
    "    'wish you the best of peace', 'wish you the best of prosperity', 'wish you the best of wealth', 'happy', 'happiness', \n",
    "    'joy', 'joyful', 'joyous', 'cheerful', 'cheers', 'cheer', 'celebrate', 'celebration', 'congratulate', 'congratulation', \n",
    "    'congratulations', 'kudos', 'kudos to', 'kudos for', 'props', 'props to', 'props for', 'salute', 'salute to', \n",
    "    'salute for', 'tribute', 'tribute to', 'tribute for', 'accolade', 'accolades', 'accolades to', 'accolades for', \n",
    "    'recognition', 'recognition to', 'recognition for', 'commend', 'commendation', 'commendations', 'commendations to', \n",
    "    'commendations for', 'commendable', 'commendable work', 'commendable job', 'commendable stuff', 'commendable one', \n",
    "    'honor', 'honor to', 'honor for', 'honored', 'honored to', 'honored for', 'pleasure', 'pleasure to', 'pleasure for', \n",
    "    'pleasure working', 'pleasure working with', 'privilege', 'privilege to', 'privilege for', 'privilege working', \n",
    "    'privilege working with', 'delight', 'delighted', 'delightful', 'delightful work', 'delightful job', 'delightful stuff', \n",
    "    'delightful one', 'pride', 'pride to', 'pride for', 'proud', 'proud to', 'proud for', 'blessed', 'blessed to', \n",
    "    'blessed for', 'blessing', 'blessing to', 'blessing for', 'gift', 'gift to', 'gift for', 'present', 'present to', \n",
    "    'present for', 'reward', 'reward to', 'reward for', 'treasure', 'treasure to', 'treasure for', 'value', 'value to', \n",
    "    'value for', 'worth', 'worth to', 'worth for', 'deserve', 'deserving', 'deserve to', 'deserve for', 'earned', \n",
    "    'earned to', 'earned for', 'merit', 'merit to', 'merit for', 'merited', 'merited to', 'merited for', 'benefit', \n",
    "    'benefit to', 'benefit for', 'benefited', 'benefited to', 'benefited for', 'gain', 'gain to', 'gain for', 'gained', \n",
    "    'gained to', 'gained for', 'advantage', 'advantage to', 'advantage for', 'advantaged', 'advantaged to', 'advantaged for', \n",
    "    'profit', 'profit to', 'profit for', 'profited', 'profited to', 'profited for', 'win', 'win to', 'win for', 'winner', \n",
    "    'winner to', 'winner for', 'winning', 'winning to', 'winning for', 'success', 'success to', 'success for', 'successful', \n",
    "    'successful to', 'successful for', 'accomplish', 'accomplishment', 'accomplishments', 'accomplishments to', 'accomplishments for', 'achieve', 'achievement', 'achievements', \n",
    "    'achievements to', 'achievements for', 'goal', 'goals', 'goals to', 'goals for', 'objective', 'objectives', \n",
    "    'objectives to', 'objectives for', 'target', 'targets', 'targets to', 'targets for', 'milestone', 'milestones', \n",
    "    'milestones to', 'milestones for', 'mark', 'marks', 'marks to', 'marks for', 'benchmark', 'benchmarks', \n",
    "    'benchmarks to', 'benchmarks for', 'standard', 'standards', 'standards to', 'standards for', 'criteria', \n",
    "    'criteria to', 'criteria for', 'score', 'scores', 'scores to', 'scores for', 'result', 'results', 'results to', \n",
    "    'results for', 'outcome', 'outcomes', 'outcomes to', 'outcomes for', 'attain', 'attainment', 'attainments', \n",
    "    'attainments to', 'attainments for', 'realize', 'realization', 'realizations', 'realizations to', 'realizations for', \n",
    "    'fulfill', 'fulfillment', 'fulfillments', 'fulfillments to', 'fulfillments for', 'meet', 'meeting', 'meetings', \n",
    "    'meetings to', 'meetings for', 'reach', 'reaches', 'reaches to', 'reaches for', 'reach to', 'reach for', 'reached', \n",
    "    'reached to', 'reached for', 'gain', 'gains', 'gains to', 'gains for', 'obtain', 'obtained', 'obtained to', \n",
    "    'obtained for', 'achieve', 'achievement', 'achievements', 'achievements to', 'achievements for', 'goal', 'goals', \n",
    "    'goals to', 'goals for', 'objective', 'objectives', 'objectives to', 'objectives for', 'target', 'targets', \n",
    "    'targets to', 'targets for', 'milestone', 'milestones', 'milestones to', 'milestones for', 'mark', 'marks', \n",
    "    'marks to', 'marks for', 'benchmark', 'benchmarks', 'benchmarks to', 'benchmarks for', 'standard', 'standards', \n",
    "    'standards to', 'standards for', 'criteria', 'criteria to', 'criteria for', 'score', 'scores', 'scores to', \n",
    "    'scores for', 'result', 'results', 'results to', 'results for', 'outcome', 'outcomes', 'outcomes to', 'outcomes for', \n",
    "    'attain', 'attainment', 'attainments', 'attainments to', 'attainments for', 'realize', 'realization', \n",
    "    'realizations', 'realizations to', 'realizations for', 'fulfill', 'fulfillment', 'fulfillments', 'fulfillments to', \n",
    "    'fulfillments for', 'meet', 'meeting', 'meetings', 'meetings to', 'meetings for', 'reach', 'reaches', 'reaches to', \n",
    "    'reaches for', 'reach to', 'reach for', 'reached', 'reached to', 'reached for', 'gain', 'gains', 'gains to', \n",
    "    'gains for', 'obtain', 'obtained', 'obtained to', 'obtained for', 'achieve', 'achievement', 'achievements', \n",
    "    'achievements to', 'achievements for', 'goal', 'goals', 'goals to', 'goals for', 'objective', 'objectives', \n",
    "    'objectives to', 'objectives for', 'target', 'targets', 'targets to', 'targets for', 'milestone', 'milestones', \n",
    "    'milestones to', 'milestones for', 'mark', 'marks', 'marks to', 'marks for', 'benchmark', 'benchmarks', \n",
    "    'benchmarks to', 'benchmarks for', 'standard', 'standards', 'standards to', 'standards for', 'criteria', 'criteria to', \n",
    "    'criteria for', 'score', 'scores', 'scores to', 'scores for', 'result', 'results', 'results to', 'results for', \n",
    "    'outcome', 'outcomes', 'outcomes to', 'outcomes for','cooper','freindless','friendless','electric ','panda'\n",
    "])\n",
    "\n",
    "# Remove stopwords and unrelated words\n",
    "def remove_stopwords_and_unrelated(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words and word.lower() not in unrelated_words])\n",
    "\n",
    "comments_cleaned = [remove_stopwords_and_unrelated(comment) for comment in comments]\n",
    "\n",
    "# Tokenize the cleaned comments\n",
    "tokenized_comments_cleaned = [nltk.word_tokenize(comment.lower()) for comment in comments_cleaned]\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "bigram = Phrases(tokenized_comments_cleaned, min_count=5, threshold=100)\n",
    "trigram = Phrases(bigram[tokenized_comments_cleaned], threshold=100)\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)\n",
    "\n",
    "# Apply bigrams and trigrams to the tokenized comments\n",
    "comments_bigrams_cleaned = [bigram_mod[comment] for comment in tokenized_comments_cleaned]\n",
    "comments_trigrams_cleaned = [trigram_mod[bigram_mod[comment]] for comment in comments_bigrams_cleaned]\n",
    "\n",
    "# Convert the n-grams back to text\n",
    "comments_unigrams_cleaned_text = [' '.join(comment) for comment in tokenized_comments_cleaned]\n",
    "comments_bigrams_cleaned_text = [' '.join(comment) for comment in comments_bigrams_cleaned]\n",
    "comments_trigrams_cleaned_text = [' '.join(comment) for comment in comments_trigrams_cleaned]\n",
    "\n",
    "def perform_lda(comments_text, ngram_range, num_topics, filename):\n",
    "    # Vectorize the text using TF-IDF with specified n-grams\n",
    "    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english', ngram_range=ngram_range)\n",
    "    tfidf_matrix = vectorizer.fit_transform(comments_text)\n",
    "    tf_feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Apply LDA\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda.fit(tfidf_matrix)\n",
    "    \n",
    "\n",
    "    # Get the top words for each topic\n",
    "    def display_topics(model, feature_names, num_top_words):\n",
    "        topics = []\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "            topics.append(top_words)\n",
    "            print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "        return topics\n",
    "\n",
    "    num_top_words = 50\n",
    "    topics = display_topics(lda, tf_feature_names, num_top_words)\n",
    "\n",
    "    # Save the topics to a CSV file\n",
    "    topics_df = pd.DataFrame(topics)\n",
    "    topics_df.to_csv(filename, index=False)\n",
    "\n",
    "    # Get the document-topic distribution\n",
    "    doc_topic_dist = lda.transform(tfidf_matrix)\n",
    "    doc_topic_dist_df = pd.DataFrame(doc_topic_dist)\n",
    "    doc_topic_dist_df.to_csv(f'doc_topic_dist_{filename}', index=False)\n",
    "\n",
    "    print(f\"Topic modeling complete. Topics saved to {filename}.\")\n",
    "    print(f\"Document-topic distribution saved to doc_topic_dist_{filename}.\")\n",
    "    print(topics_df.head())\n",
    "    print(doc_topic_dist_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Perform LDA for trigrams (5 topics)\n",
    "print(\"\\nTrigrams (5 topics):\")\n",
    "perform_lda(comments_trigrams_cleaned_text, (3, 3), 5, 'lda_topics_trigrams_cleaned.csv')\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Prepare the dictionary and corpus for Gensim\n",
    "dictionary = corpora.Dictionary(tokenized_comments_cleaned)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_comments_cleaned]\n",
    "\n",
    "# Train the LDA model using Gensim\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=42, passes=10)\n",
    "# Calculate the coherence score\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, texts=tokenized_comments_cleaned, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherence Score: {coherence_score}\")\n",
    "\n",
    "\n",
    "# Visualize the topics using pyLDAvis\n",
    "lda_vis_data = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "# Save the visualization as an HTML file\n",
    "output_file_path = 'fiat_topic.html'\n",
    "pyLDAvis.save_html(lda_vis_data, output_file_path)\n",
    "\n",
    "# Display the visualization directly in the Jupyter notebook\n",
    "from IPython.display import display\n",
    "display(pyLDAvis.display(lda_vis_data))\n",
    "\n",
    "print(f\"Topic visualization saved to {output_file_path}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import webbrowser\n",
    "\n",
    "def visualize_gensim_lda(optimal_model, corpus, id2word, filename):\n",
    "    # Prepare the visualization data\n",
    "    vis_data = gensimvis.prepare(optimal_model, corpus, id2word)\n",
    "    \n",
    "    # Save the visualization as an HTML file\n",
    "    pyLDAvis.save_html(vis_data, filename)\n",
    "    pyLDAvis.display(vis_data)\n",
    "    display(pyLDAvis.display(vis_data))\n",
    "    \n",
    "    # Open the visualization in the default web browser\n",
    "    webbrowser.open('file://' + filename)\n",
    "    print(f\"LDA visualization saved to {filename} and opened in the default web browser.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Comments for Each Topic Based on LDA Weights\n",
    "\n",
    "In this step, we extracted YouTube comments associated with each topic identified by the LDA model, using the document-topic distribution. Comments were filtered based on their topic weights to ensure that only those with significant relevance to a topic were selected.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Loading the Dataset**:\n",
    "   - The dataset containing translated comments was loaded from the CSV file (`translated_comments_with_plain_texts.csv`).\n",
    "   - Any rows with missing values in the `translated_plain_texts` column were removed to ensure clean data.\n",
    "\n",
    "2. **Extracting Comments Based on Topic Weights**:\n",
    "   - A function `extract_comments_for_topics_with_weights` was defined to extract comments that have a significant association with each topic.\n",
    "   - The function takes the following inputs:\n",
    "     - **Document-Topic Distribution File**: The CSV file containing the distribution of topics across all comments (`doc_topic_dist_lda_topics_trigrams_cleaned.csv`).\n",
    "     - **Comments**: The list of comments from the dataset.\n",
    "     - **Number of Topics**: The total number of topics identified by the LDA model (5 topics in this case).\n",
    "     - **Output Prefix**: The prefix used for naming the output files containing the extracted comments.\n",
    "     - **Threshold**: A threshold of 0.3 was set to filter out comments with low relevance to a topic, ensuring that only comments with a higher probability of belonging to a topic were selected.\n",
    "\n",
    "3. **Saving Extracted Comments**:\n",
    "   - For each topic, comments with a topic weight greater than the threshold were extracted along with their corresponding weights.\n",
    "   - These comments were saved to separate CSV files, one for each topic. The files were named using the specified output prefix (`trigrams_topic_<number>_comments.csv`).\n",
    "\n",
    "4. **Summary of Outputs**:\n",
    "   - The function successfully extracted and saved comments for each of the 5 topics, filtering out less relevant comments based on their topic weights.\n",
    "\n",
    "### Summary:\n",
    "This step allowed for the extraction of comments that are strongly associated with each identified topic, based on their LDA-derived topic weights. By setting a threshold, we ensured that the extracted comments are highly relevant to their respective topics, which is crucial for further analysis, such as thematic exploration or sentiment analysis within each topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the translated dataset\n",
    "file_path = 'translated_comments_with_plain_texts.csv'  # Update with the correct path\n",
    "translated_data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the dataset has no NaN values in the 'translated_plain_texts' column\n",
    "translated_data = translated_data.dropna(subset=['translated_plain_texts'])\n",
    "\n",
    "# Extract the comments\n",
    "comments = translated_data['translated_plain_texts'].tolist()\n",
    "\n",
    "def extract_comments_for_topics_with_weights(doc_topic_dist_file, comments, num_topics, output_prefix, threshold=0.3):\n",
    "    # Load the document-topic distribution\n",
    "    doc_topic_dist = pd.read_csv(doc_topic_dist_file)\n",
    "    \n",
    "    # Ensure the number of topics matches\n",
    "    if doc_topic_dist.shape[1] != num_topics:\n",
    "        raise ValueError(f\"Number of topics in {doc_topic_dist_file} does not match the expected number of topics ({num_topics}).\")\n",
    "\n",
    "    for topic in range(num_topics):\n",
    "        # Extract comments and their weights (probabilities) for this topic\n",
    "        topic_comments_weights = [(comments[i], doc_topic_dist.iloc[i, topic]) for i in range(len(comments)) if doc_topic_dist.iloc[i, topic] > threshold]\n",
    "        \n",
    "        # Save the comments and their weights to a CSV file\n",
    "        output_file = f\"{output_prefix}_topic_{topic + 1}_comments.csv\"\n",
    "        pd.DataFrame(topic_comments_weights, columns=[\"Comment\", \"Weight\"]).to_csv(output_file, index=False)\n",
    "        print(f\"Comments and weights for Topic {topic + 1} saved to {output_file}\")\n",
    "\n",
    "# Extract comments for trigrams (5 topics)\n",
    "extract_comments_for_topics_with_weights('doc_topic_dist_lda_topics_trigrams_cleaned.csv', comments, 5, 'trigrams')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Comments Based on Topic Weights\n",
    "\n",
    "In this step, the comments associated with each topic were categorized into three levels of importance based on their topic weights. The categorization was guided by statistical thresholds (mean and standard deviation) calculated for each topic.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Thresholds Calculation**:\n",
    "   - The mean and standard deviation of the topic weights were calculated for each of the 5 topics. These statistics were used to define the thresholds for categorizing comments:\n",
    "     - **Most Important Comments**: Comments with weights greater than `mean + std_dev`.\n",
    "     - **Important Comments**: Comments with weights between `mean - std_dev` and `mean + std_dev`.\n",
    "     - **Least Important Comments**: Comments with weights less than `mean - std_dev`.\n",
    "\n",
    "   ```python\n",
    "   # Example of thresholds for Topic 1\n",
    "   thresholds = {\n",
    "       1: {\"mean\": 0.6985, \"std_dev\": 0.1060},\n",
    "       # Similarly for other topics...\n",
    "   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define thresholds for each topic\n",
    "thresholds = {\n",
    "    1: {\"mean\": 0.6985, \"std_dev\": 0.1060},\n",
    "    2: {\"mean\": 0.6915, \"std_dev\": 0.0999},\n",
    "    3: {\"mean\": 0.7124, \"std_dev\": 0.1008},\n",
    "    4: {\"mean\": 0.7100, \"std_dev\": 0.1092},\n",
    "    5: {\"mean\": 0.6935, \"std_dev\": 0.1034}\n",
    "}\n",
    "\n",
    "# Directory path\n",
    "directory_path = \"/Users/abhishekroy/Downloads/vscode folder\"\n",
    "\n",
    "for topic_num in range(1, 6):\n",
    "    # Load the comments for the current topic\n",
    "    topic_df = pd.read_csv(f'{directory_path}/trigrams_topic_{topic_num}_comments.csv')\n",
    "\n",
    "    # Get the thresholds for the current topic\n",
    "    mean_weight = thresholds[topic_num][\"mean\"]\n",
    "    std_dev = thresholds[topic_num][\"std_dev\"]\n",
    "    most_important_threshold = mean_weight + std_dev\n",
    "    least_important_threshold = mean_weight - std_dev\n",
    "\n",
    "    # Categorize the comments based on the thresholds\n",
    "    most_important_comments = topic_df[topic_df['Weight'] > most_important_threshold]\n",
    "    important_comments = topic_df[(topic_df['Weight'] <= most_important_threshold) & (topic_df['Weight'] >= least_important_threshold)]\n",
    "    least_important_comments = topic_df[topic_df['Weight'] < least_important_threshold]\n",
    "\n",
    "    # Save the categorized comments to CSV files\n",
    "    most_important_comments.to_csv(f'{directory_path}/most_important_comments_topic_{topic_num}.csv', index=False)\n",
    "    important_comments.to_csv(f'{directory_path}/important_comments_topic_{topic_num}.csv', index=False)\n",
    "    least_important_comments.to_csv(f'{directory_path}/least_important_comments_topic_{topic_num}.csv', index=False)\n",
    "\n",
    "    print(f\"Categorized comments for Topic {topic_num} have been saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating Comments Across Topics and Categories\n",
    "\n",
    "In this step, the most relevant comments from each topic and category were aggregated into a single dataset. This process involved selecting a subset of comments from different levels of importance across all identified topics.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Directory Setup**:\n",
    "   - The directory path was specified to locate the categorized comment files (`most_important`, `important`, `least_important`) for each topic.\n",
    "\n",
    "2. **Initialization of Aggregated DataFrame**:\n",
    "   - An empty Pandas DataFrame was initialized to store the aggregated comments from all topics and categories.\n",
    "\n",
    "3. **Looping Through Topics and Categories**:\n",
    "   - For each of the 5 topics, and within each topic, for each of the three categories (`most_important`, `important`, `least_important`):\n",
    "     - The corresponding CSV file containing the comments was loaded.\n",
    "     - The first 10 comments from each file were selected for inclusion in the aggregated dataset.\n",
    "     - Additional columns were added to indicate the `Category` (importance level) and `Topic` to which each comment belongs.\n",
    "\n",
    "4. **Appending to Aggregated DataFrame**:\n",
    "   - The selected comments were appended to the aggregated DataFrame, maintaining the structure and categorization.\n",
    "\n",
    "5. **Saving the Aggregated Data**:\n",
    "   - The final aggregated DataFrame, containing a representative subset of comments across all topics and categories, was saved to a new CSV file (`aggregated_comments.csv`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Directory path\n",
    "directory_path = \"/Users/abhishekroy/Downloads/vscode folder\"\n",
    "\n",
    "# Initialize an empty DataFrame to store the comments\n",
    "aggregated_comments = pd.DataFrame()\n",
    "\n",
    "# Loop through each topic and category to aggregate comments\n",
    "for topic_num in range(1, 6):\n",
    "    for category in [\"most_important\", \"important\", \"least_important\"]:\n",
    "        # Load the comments for the current category and topic\n",
    "        comments_df = pd.read_csv(f'{directory_path}/{category}_comments_topic_{topic_num}.csv')\n",
    "        \n",
    "        # Get the first 10 comments\n",
    "        comments_subset = comments_df.head(10).copy()\n",
    "        \n",
    "        # Add columns to indicate category and topic\n",
    "        comments_subset['Category'] = category\n",
    "        comments_subset['Topic'] = f'Topic {topic_num}'\n",
    "        \n",
    "        # Append to the aggregated DataFrame\n",
    "        aggregated_comments = pd.concat([aggregated_comments, comments_subset], ignore_index=True)\n",
    "\n",
    "# Save the aggregated comments to a new CSV file\n",
    "output_file = f'{directory_path}/aggregated_comments.csv'\n",
    "aggregated_comments.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated comments saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning BART Model for Text Summarization\n",
    "\n",
    "In this step, the BART (Bidirectional and Auto-Regressive Transformers) model was fine-tuned for text summarization using a few-shot learning approach. The dataset used for fine-tuning was derived from the aggregated file of comments from different topics and categories, providing a comprehensive and representative sample for training.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Device Configuration**:\n",
    "   - The script automatically detected the best available device for training, using MPS (Metal Performance Shaders) on macOS, CUDA (GPU) if available, or falling back to CPU.\n",
    "\n",
    "2. **Model and Tokenizer Initialization**:\n",
    "   - The BART model (`suriya7/bart-finetuned-text-summarization`) and its corresponding tokenizer were loaded from Hugging Face's model repository.\n",
    "   - Special tokens (`decoder_start_token_id`, `pad_token_id`) were configured to ensure proper handling of sequences.\n",
    "\n",
    "3. **Loading Few-Shot Examples**:\n",
    "   - The dataset for fine-tuning was created from the aggregated file of comments across all topics and categories (`aggregated_comments.csv`). This file provided a balanced and varied sample of comments to train the model effectively.\n",
    "   - The examples were loaded from a CSV file (`XYZfnal fine tue xample.csv`) containing input texts and their corresponding target summaries.\n",
    "\n",
    "4. **Text Chunking**:\n",
    "   - Given that the input text may exceed the model's maximum sequence length, a chunking function was defined to split the text into smaller, overlapping chunks.\n",
    "   - This chunking was applied during preprocessing to both the input and target texts, ensuring that the model could process long sequences effectively.\n",
    "\n",
    "5. **Dataset Preparation**:\n",
    "   - The few-shot examples were converted into a `Dataset` object compatible with Hugging Face's `transformers` library.\n",
    "   - The dataset was tokenized and prepared for training, with attention paid to chunking and sequence padding.\n",
    "\n",
    "6. **Training Configuration**:\n",
    "   - Training arguments were specified, including a learning rate of `6e-5`, a batch size of `4`, and an increased number of epochs (`45`) due to the small dataset size.\n",
    "   - Evaluation during training was disabled to streamline the process.\n",
    "\n",
    "7. **Model Fine-Tuning**:\n",
    "   - The BART model was fine-tuned on the prepared few-shot dataset using the `Seq2SeqTrainer` class.\n",
    "   - The training process adapted the model to the specific text summarization task at hand.\n",
    "\n",
    "8. **Saving the Fine-Tuned Model**:\n",
    "   - The fine-tuned model and tokenizer were saved to a directory (`./fine-tuned-model`) for later use.\n",
    "\n",
    "9. **Summary Generation Function**:\n",
    "   - A function was defined to generate summaries from input texts using the fine-tuned model.\n",
    "   - This function handles long texts by chunking them, generating summaries for each chunk, and combining them into a final summary.\n",
    "\n",
    "### Summary:\n",
    "This fine-tuning step adapted a pre-trained BART model for the specific task of summarizing YouTube comments and other related text data. The dataset used for training was carefully curated from an aggregated file that combined comments across all identified topics and categories, ensuring a rich and varied input for the model. By utilizing a few-shot learning approach, the model was trained on this dataset with careful handling of long sequences, making it suitable for generating accurate and concise summaries. The fine-tuned model is now ready to be used for summarization tasks on similar datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_built() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set the Hugging Face model repo\n",
    "model_name = \"suriya7/bart-finetuned-text-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Ensure special tokens are set\n",
    "model.config.decoder_start_token_id = model.config.decoder_start_token_id or tokenizer.bos_token_id\n",
    "model.config.pad_token_id = model.config.pad_token_id or tokenizer.pad_token_id\n",
    "\n",
    "# Load the few-shot examples with correct column names\n",
    "few_shot_examples_path = \"/Users/abhishekroy/Downloads/vscode folder/XYZfnal fine tue xample.csv\"\n",
    "few_shot_df = pd.read_csv(few_shot_examples_path)\n",
    "\n",
    "# Chunking function\n",
    "def chunk_text(text, chunk_size=512, overlap=50):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + chunk_size, len(tokens))\n",
    "        chunk = tokenizer.convert_tokens_to_string(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# Apply chunking in preprocessing\n",
    "def preprocess_chunked_function(examples):\n",
    "    chunked_input_texts = []\n",
    "    chunked_target_texts = []\n",
    "    for input_text, target_text in zip(examples[\"input_text\"], examples[\"target_text\"]):\n",
    "        input_chunks = chunk_text(input_text)\n",
    "        target_chunks = chunk_text(target_text)\n",
    "        for input_chunk, target_chunk in zip(input_chunks, target_chunks):\n",
    "            chunked_input_texts.append(input_chunk)\n",
    "            chunked_target_texts.append(target_chunk)\n",
    "    \n",
    "    inputs = tokenizer(chunked_input_texts, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    targets = tokenizer(chunked_target_texts, max_length=150, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    inputs[\"labels\"] = [[label if label != tokenizer.pad_token_id else -100 for label in labels] for labels in inputs[\"labels\"]]\n",
    "    return inputs\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "few_shot_dataset = Dataset.from_pandas(few_shot_df)\n",
    "tokenized_few_shot_dataset = few_shot_dataset.map(preprocess_chunked_function, batched=True)\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"no\",  # Disable evaluation\n",
    "    learning_rate=6e-5,  # 3e-5 was best before; trying a slight variation\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    use_cpu=True,\n",
    "    num_train_epochs=45,  # Increase epochs due to small dataset\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_few_shot_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "trainer.save_model(\"./fine-tuned-model\")\n",
    "tokenizer.save_pretrained(\"./fine-tuned-model\")\n",
    "\n",
    "# Function to generate summaries with chunking\n",
    "def generate_summary(text, model, tokenizer, chunk_size=512, overlap=50):\n",
    "    # Step 1: Chunk the input text\n",
    "    chunks = chunk_text(text, chunk_size=chunk_size, overlap=overlap)\n",
    "    \n",
    "    # Step 2: Generate summaries for each chunk\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", max_length=chunk_size, truncation=True).to(device)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # Step 3: Combine the summaries into a final summary\n",
    "    final_summary = \" \".join(summaries)\n",
    "    return final_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Summaries for Each Topic and Category\n",
    "\n",
    "In this step, summaries were generated for the most important, important, and least important comments within each topic using the fine-tuned BART model. These summaries were compiled into Word documents for easy review and analysis.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Device Configuration**:\n",
    "   - The script automatically selected the best available device for running the model, using MPS (Metal Performance Shaders) on macOS, CUDA (GPU) if available, or falling back to CPU.\n",
    "\n",
    "2. **Loading the Fine-Tuned Model and Tokenizer**:\n",
    "   - The fine-tuned BART model and its corresponding tokenizer were loaded from the specified directory (`./fine-tuned-model`).\n",
    "\n",
    "3. **Defining the Summary Generation Function**:\n",
    "   - A function `generate_summary` was defined to generate a summary for a given text. The function handles tokenization, model inference, and decoding to produce a concise summary of the input text.\n",
    "\n",
    "4. **Iterating Over Topics and Categories**:\n",
    "   - For each of the 5 topics, and within each topic, for each of the three categories (`most_important`, `important`, `least_important`):\n",
    "     - The corresponding CSV file containing the comments was loaded.\n",
    "     - The number of comments and the average weight for each category were calculated.\n",
    "     - All comments within a category were concatenated into a single text block.\n",
    "     - The concatenated text was summarized using the fine-tuned BART model.\n",
    "\n",
    "5. **Compiling Summaries into Word Documents**:\n",
    "   - The generated summaries were compiled into Word documents (`NEW Topic_<number>_summaries.docx`), with each document containing summaries for all three categories within a topic.\n",
    "   - Each document included the following details:\n",
    "     - **Number of comments**: Total count of comments in the category.\n",
    "     - **Average weight**: The average topic weight of the comments in the category (if available).\n",
    "     - **Summary**: A concise summary generated by the model for all comments in the category.\n",
    "\n",
    "6. **Progress Tracking**:\n",
    "   - A progress bar was used to track the processing of topics and categories, providing real-time feedback on the script's execution.\n",
    "\n",
    "7. **Saving the Documents**:\n",
    "   - The Word documents were saved to the specified directory, with filenames indicating the topic number (e.g., `NEW Topic_1_summaries.docx`).\n",
    "\n",
    "### Summary:\n",
    "This step involved summarizing the most relevant comments across different categories for each topic using a fine-tuned BART model. The resulting summaries were compiled into Word documents, providing a structured and concise overview of the key discussions within each topic. These documents are valuable for quickly understanding the general sentiment and key points expressed in the YouTube comments related to the Fiat 500 Dolcevita.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from docx import Document\n",
    "\n",
    "# Check if MPS is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_built() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = \"./fine-tuned-model\"  # Path to the fine-tuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Function to generate summaries\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], num_beams=4, max_length=150, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Initialize the progress bar\n",
    "total_steps = 5 * 3  # 5 topics and 3 categories per topic\n",
    "progress_bar = tqdm(total=total_steps, desc=\"Processing\")\n",
    "\n",
    "# Load the comments for each category in each topic and generate summaries\n",
    "for topic_num in range(1, 6):\n",
    "    document = Document()\n",
    "    document.add_heading(f'Topic {topic_num}', level=1)\n",
    "    \n",
    "    for category in ['most_important', 'important', 'least_important']:\n",
    "        comments_path = f'/Users/abhishekroy/Downloads/vscode folder/{category}_comments_topic_{topic_num}.csv'\n",
    "        comments_df = pd.read_csv(comments_path)\n",
    "        \n",
    "        # Calculate the number of comments and average weight of each aspect\n",
    "        num_comments = len(comments_df)\n",
    "        if 'Weight' in comments_df.columns:\n",
    "            average_weight = comments_df['Weight'].mean()\n",
    "        else:\n",
    "            average_weight = 'N/A'\n",
    "        \n",
    "        # Concatenate all comments in the category\n",
    "        all_comments = \" \".join(comments_df['Comment'].tolist())\n",
    "        \n",
    "        # Generate a summary for all comments together\n",
    "        summary = generate_summary(all_comments)\n",
    "        \n",
    "        # Add the summary to the document\n",
    "        document.add_heading(f'{category.replace(\"_\", \" \").title()} Comments Summary', level=2)\n",
    "        document.add_paragraph(f'Number of comments: {num_comments}')\n",
    "        document.add_paragraph(f'Average weight: {average_weight}')\n",
    "        document.add_paragraph(summary)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    # Save the document\n",
    "    document_path = f'/Users/abhishekroy/Downloads/vscode folder/NEW Topic_{topic_num}_summaries.docx'\n",
    "    document.save(document_path)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of the Output\n",
    "\n",
    "### Topic 1\n",
    "\n",
    "#### **Most Important Comments Summary**\n",
    "- **Number of comments**: 145\n",
    "- **Average weight**: 0.8505\n",
    "- **Summary**: Owners of the Fiat Dolcevita frequently praise its stylish and chic design, describing the car as \"cute\" and \"beautiful.\" The glossy white and shiny pink color options are particularly well-received. The car evokes strong emotional connections, with many expressing joy and happiness from driving it, as well as a sense of pride in ownership—even among those who bought it impulsively. The Fiat Dolcevita is often described as a pleasure to drive, appreciated for its comfortable and responsive driving experience. It is seen as a perfect match for those who value style and uniqueness, making it not just a car but a lifestyle statement. Socially, the car enjoys a positive perception, with owners receiving compliments and noting how it impacts their social interactions.\n",
    "\n",
    "#### **Important Comments Summary**\n",
    "- **Number of comments**: 738\n",
    "- **Average weight**: 0.5610\n",
    "- **Summary**: Owners and admirers of the Fiat Dolcevita appreciate its stylish and sophisticated design, often commenting on its aesthetic appeal. The car is described as \"cute\" and \"beautiful,\" with particular admiration for its color combinations and the luxurious feel of the interior, including leather seats, wood accents, and chrome body stripes. Many find joy in driving it, noting that it enhances their overall experience with its fun and comfortable driving dynamics. The Fiat Dolcevita is seen as a perfect match for those who value both elegance and performance, with owners enjoying both aspects of its design and the joy it brings to their lives. Social interactions play a significant role, with the car being a frequent topic of conversation.\n",
    "\n",
    "#### **Least Important Comments Summary**\n",
    "- **Number of comments**: 2\n",
    "- **Average weight**: 0.3684\n",
    "- **Summary**: The least important comments about the Fiat Dolcevita are more scattered and less focused on the core aspects of the car itself. These comments often drift into unrelated topics, such as plant descriptions or general expressions of admiration. While some references to the car's \"cute\" and \"adorable\" design can be inferred, these comments do not contribute significantly to the overall public perception of the car. The minimal direct feedback suggests that these comments reflect more niche or personal musings rather than substantive evaluations of the vehicle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Customer Reviews with Fiat's Marketing Messages\n",
    "\n",
    "In this step, we analyzed how well customer reviews align with Fiat's marketing messages by comparing the textual similarity and sentiment correlation between the two datasets. This analysis was visualized using heatmaps that provide insights into the alignment between customer perceptions and marketing strategies.\n",
    "\n",
    "#### Steps Performed:\n",
    "\n",
    "1. **Device Configuration**:\n",
    "   - The script detected the best available device (MPS, CUDA, or CPU) for running the model, ensuring efficient processing of the data.\n",
    "\n",
    "2. **Model and Tools Initialization**:\n",
    "   - The `Sentence-BERT` model (`stsb-roberta-large`) was loaded to generate embeddings for the text data. This model is specifically designed to measure semantic similarity between sentences.\n",
    "   - The VADER sentiment analyzer was initialized to calculate sentiment scores for both customer reviews and marketing content.\n",
    "   - Stopwords were removed from the text data to focus on the most meaningful words and phrases.\n",
    "\n",
    "3. **Loading and Preprocessing Data**:\n",
    "   - The customer reviews were loaded from a JSON file (`review label data _Modeling_Data.json`), and the marketing content was loaded from another JSON file (`XXmarketinTopic_Modeling_Data.json`).\n",
    "   - Both datasets were preprocessed to remove stopwords, ensuring that the analysis focuses on the most relevant content.\n",
    "\n",
    "4. **Matching Labels and Preparing Matrices**:\n",
    "   - The labels (topics) present in both the customer reviews and marketing content were identified and matched.\n",
    "   - Two empty matrices were created to store the results of the analysis: one for cosine similarity and one for sentiment correlation.\n",
    "\n",
    "5. **Cosine Similarity and Sentiment Analysis**:\n",
    "   - For each matched label, the following steps were performed:\n",
    "     - **Embedding Generation**: The text content for each label was converted into embeddings using the `Sentence-BERT` model.\n",
    "     - **Cosine Similarity Calculation**: The cosine similarity between the embeddings of customer reviews and marketing content was calculated, indicating how similar the two texts are in terms of content.\n",
    "     - **Sentiment Analysis**: The sentiment scores for both texts were computed using VADER, and the correlation between the sentiments was calculated by measuring the absolute difference.\n",
    "\n",
    "6. **Creating and Displaying Heatmaps**:\n",
    "   - **Cosine Similarity Heatmap**: A heatmap was generated to visualize the alignment between customer reviews and marketing messages based on cosine similarity.\n",
    "   - **Sentiment Correlation Heatmap**: A second heatmap was created to show how closely the sentiment in customer reviews aligns with the sentiment conveyed in marketing content.\n",
    "   - Custom color scales were used to enhance the visualization, with darker green indicating higher similarity or sentiment correlation.\n",
    "\n",
    "7. **Insights from Heatmaps**:\n",
    "   - The heatmaps provide a clear visual representation of how well customer perceptions align with Fiat's marketing strategies, both in terms of content and sentiment.\n",
    "\n",
    "### Summary:\n",
    "This analysis compared customer reviews with Fiat's marketing content, focusing on both textual similarity and sentiment alignment. The resulting heatmaps offer valuable insights into how closely customer opinions mirror the messages conveyed by Fiat's marketing efforts. These visualizations can help identify areas where marketing strategies are effectively resonating with customers and where there may be discrepancies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekroy/miniforge3/envs/myenv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/abhishekroy/miniforge3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:242: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  interpolation: int = Image.BILINEAR,\n",
      "/Users/abhishekroy/miniforge3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:288: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "/Users/abhishekroy/miniforge3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:304: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "/Users/abhishekroy/miniforge3/envs/myenv/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:321: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  interpolation: int = Image.BICUBIC,\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhishekroy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Customer Review Topics: %{x}<br>Fiat Marketing Topics: %{y}<br>Similarity: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "YT Review: Build Quality & Materials",
          "YT Review: Design & Aesthetics",
          "YT Review: Lifestyle & Heritage",
          "YT Review: Specifications & Performance",
          "YT Review: Technology & Features"
         ],
         "xaxis": "x",
         "y": [
          "Fiat: Build Quality & Materials",
          "Fiat: Design & Aesthetics",
          "Fiat: Lifestyle & Heritage",
          "Fiat: Specifications & Performance",
          "Fiat: Technology & Features"
         ],
         "yaxis": "y",
         "z": [
          [
           0.4972671568393707,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.5682300329208374,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0.5575928092002869,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0.374872624874115,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0.20664721727371216
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "len": 300,
          "lenmode": "pixels",
          "thickness": 10,
          "thicknessmode": "pixels",
          "title": {
           "text": "Similarity"
          }
         },
         "colorscale": [
          [
           0,
           "rgba(0, 0, 0, 0)"
          ],
          [
           0.00001,
           "rgb(255, 0, 0)"
          ],
          [
           0.3,
           "rgb(255, 165, 0)"
          ],
          [
           0.5,
           "rgb(255, 255, 0)"
          ],
          [
           0.7,
           "rgb(0, 128, 0)"
          ],
          [
           1,
           "rgb(0, 100, 0)"
          ]
         ]
        },
        "height": 800,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "How Well Do Customer Reviews Align with Fiat's Marketing Messages?"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Customer Review Topics"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Fiat Marketing Topics"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Customer Review Topics: %{x}<br>Fiat Marketing Topics: %{y}<br>Sentiment Correlation: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "YT Review: Build Quality & Materials",
          "YT Review: Design & Aesthetics",
          "YT Review: Lifestyle & Heritage",
          "YT Review: Specifications & Performance",
          "YT Review: Technology & Features"
         ],
         "xaxis": "x",
         "y": [
          "Fiat: Build Quality & Materials",
          "Fiat: Design & Aesthetics",
          "Fiat: Lifestyle & Heritage",
          "Fiat: Specifications & Performance",
          "Fiat: Technology & Features"
         ],
         "yaxis": "y",
         "z": [
          [
           0.7826,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0.9501000000000001,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0.9979,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0.45419999999999994,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0.5592
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "len": 300,
          "lenmode": "pixels",
          "thickness": 10,
          "thicknessmode": "pixels",
          "title": {
           "text": "Sentiment Correlation"
          }
         },
         "colorscale": [
          [
           0,
           "rgba(0, 0, 0, 0)"
          ],
          [
           0.00001,
           "rgb(255, 0, 0)"
          ],
          [
           0.3,
           "rgb(255, 165, 0)"
          ],
          [
           0.5,
           "rgb(255, 255, 0)"
          ],
          [
           0.7,
           "rgb(0, 128, 0)"
          ],
          [
           1,
           "rgb(0, 100, 0)"
          ]
         ]
        },
        "height": 800,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentiment Alignment Between Customer Reviews and Fiat's Marketing"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Customer Review Topics"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Fiat Marketing Topics"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.express as px\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords from NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "# Check if MPS is available and set the device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_built() else torch.device(\"cpu\")\n",
    "\n",
    "# Load the STS model (Sentence-BERT)\n",
    "sts_model = SentenceTransformer('stsb-roberta-large').to(device)\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load the new JSON file with customer reviews\n",
    "review_data = pd.read_json('/Users/abhishekroy/Downloads/vscode folder/review label data _Modeling_Data.json')\n",
    "review_data['content'] = review_data['content'].apply(remove_stopwords)\n",
    "\n",
    "# Load the marketing data\n",
    "marketing_data = pd.read_json('/Users/abhishekroy/Downloads/vscode folder/XXmarketinTopic_Modeling_Data.json')\n",
    "marketing_data['content'] = marketing_data['content'].apply(remove_stopwords)\n",
    "\n",
    "# Filter and compute similarity and sentiment for matching labels\n",
    "matching_labels = set(review_data['label']).intersection(set(marketing_data['label']))\n",
    "\n",
    "# Create empty matrices for the heatmaps\n",
    "n_labels = len(matching_labels)\n",
    "similarity_matrix_diag = np.zeros((n_labels, n_labels))\n",
    "sentiment_matrix_diag = np.zeros((n_labels, n_labels))\n",
    "\n",
    "# Sort and prepend \"Fiat\" and \"YT Review\" to labels\n",
    "matching_labels = sorted(matching_labels)  # Sort to maintain consistency\n",
    "review_labels = [\"YT Review: \" + label for label in matching_labels]\n",
    "marketing_labels = [\"Fiat: \" + label for label in matching_labels]\n",
    "\n",
    "for idx, label in enumerate(matching_labels):\n",
    "    review_content = review_data[review_data['label'] == label]['content'].values[0]\n",
    "    marketing_content = marketing_data[marketing_data['label'] == label]['content'].values[0]\n",
    "    \n",
    "    # Generate embeddings\n",
    "    review_embedding = sts_model.encode(review_content, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
    "    marketing_embedding = sts_model.encode(marketing_content, convert_to_tensor=True).cpu().numpy().reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity and store it in the diagonal of the matrix\n",
    "    similarity = cosine_similarity(review_embedding, marketing_embedding).flatten()[0]\n",
    "    similarity_matrix_diag[idx, idx] = similarity\n",
    "    \n",
    "    # Calculate sentiment for review and marketing content\n",
    "    review_sentiment = analyzer.polarity_scores(review_content)['compound']\n",
    "    marketing_sentiment = analyzer.polarity_scores(marketing_content)['compound']\n",
    "    \n",
    "    # Calculate the absolute difference between the sentiments and store it in the diagonal matrix\n",
    "    sentiment_correlation = 1 - abs(review_sentiment - marketing_sentiment)\n",
    "    sentiment_matrix_diag[idx, idx] = sentiment_correlation\n",
    "\n",
    "# Convert the matrices into dataframes for better visualization\n",
    "similarity_df = pd.DataFrame(similarity_matrix_diag, index=marketing_labels, columns=review_labels)\n",
    "sentiment_df = pd.DataFrame(sentiment_matrix_diag, index=marketing_labels, columns=review_labels)\n",
    "\n",
    "# Create a custom color scale for the heatmap\n",
    "color_scale = [\n",
    "    [0.0, 'rgba(0, 0, 0, 0)'],  # Transparent for zeros\n",
    "    [0.00001, 'rgb(255, 0, 0)'],  # Red for small values\n",
    "    [0.3, 'rgb(255, 165, 0)'],  # Orange\n",
    "    [0.5, 'rgb(255, 255, 0)'],  # Yellow\n",
    "    [0.7, 'rgb(0, 128, 0)'],  # Green\n",
    "    [1.0, 'rgb(0, 100, 0)']  # Dark Green for high values\n",
    "]\n",
    "\n",
    "# Create the cosine similarity heatmap\n",
    "fig1 = px.imshow(\n",
    "    similarity_df,\n",
    "    labels=dict(x=\"Customer Review Topics\", y=\"Fiat Marketing Topics\", color=\"Similarity\"),\n",
    "    color_continuous_scale=color_scale,\n",
    "    text_auto=True\n",
    ")\n",
    "fig1.update_layout(\n",
    "    title=\"How Well Do Customer Reviews Align with Fiat's Marketing Messages?\",\n",
    "    xaxis_title=\"Customer Review Topics\",\n",
    "    yaxis_title=\"Fiat Marketing Topics\",\n",
    "    width=800,\n",
    "    height=800,\n",
    "    coloraxis_colorbar=dict(title=\"Similarity\", thicknessmode=\"pixels\", thickness=10, lenmode=\"pixels\", len=300),\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# Create the sentiment correlation heatmap\n",
    "fig2 = px.imshow(\n",
    "    sentiment_df,\n",
    "    labels=dict(x=\"Customer Review Topics\", y=\"Fiat Marketing Topics\", color=\"Sentiment Correlation\"),\n",
    "    color_continuous_scale=color_scale,\n",
    "    text_auto=True\n",
    ")\n",
    "fig2.update_layout(\n",
    "    title=\"Sentiment Alignment Between Customer Reviews and Fiat's Marketing\",\n",
    "    xaxis_title=\"Customer Review Topics\",\n",
    "    yaxis_title=\"Fiat Marketing Topics\",\n",
    "    width=800,\n",
    "    height=800,\n",
    "    coloraxis_colorbar=dict(title=\"Sentiment Correlation\", thicknessmode=\"pixels\", thickness=10, lenmode=\"pixels\", len=300),\n",
    ")\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Files Overview\n",
    "\n",
    "### 1. **Customer Review Data (review label data _Modeling_Data.json)**\n",
    "\n",
    "The `review label data _Modeling_Data.json` file contains detailed summaries derived from customer reviews about the Fiat Dolcevita. These reviews are categorized into several key topics, reflecting customers' opinions and experiences with the vehicle. The main topics include:\n",
    "\n",
    "- **Design & Aesthetics**: Customers often praise the Fiat Dolcevita for its stylish and chic design, including its color options, interior materials, and overall aesthetic appeal. The car's design is frequently described as iconic, luxurious, and uniquely Italian.\n",
    "\n",
    "- **Lifestyle & Heritage**: The Fiat Dolcevita is more than just a car for many owners; it represents a lifestyle. Reviews emphasize the emotional connection owners have with the car, often tied to Italian cultural heritage and the joyful experiences associated with driving it.\n",
    "\n",
    "- **Specifications & Performance**: Opinions on the car's performance are mixed, with some owners appreciating its driving dynamics and comfort, while others express concerns about power output and the functionality of certain features, particularly in hybrid models.\n",
    "\n",
    "- **Technology & Features**: While the car's technology, such as infotainment systems and safety features, is generally appreciated, there are some concerns about the lack of advanced options and the effectiveness of the hybrid system.\n",
    "\n",
    "- **Build Quality & Materials**: The build quality is praised, particularly for the use of high-quality materials in the interior. However, practical concerns like heavy doors and frequent refueling needs are noted.\n",
    "\n",
    "This dataset was created by aggregating and summarizing various customer reviews, focusing on specific aspects of the Fiat Dolcevita that are important to users.\n",
    "\n",
    "### 2. **Fiat Marketing Content (XXmarketinTopic_Modeling_Data.json)**\n",
    "\n",
    "The `XXmarketinTopic_Modeling_Data.json` file compiles content from Fiat's marketing materials, press releases, and guides about the Fiat Dolcevita. The content is categorized into several key topics that highlight Fiat's branding and product features:\n",
    "\n",
    "- **Lifestyle & Heritage**: Fiat markets the Dolcevita as a symbol of the \"Dolce Vita\" lifestyle, emphasizing Italian culture, elegance, and a carefree approach to life. This narrative is deeply rooted in the car's design and marketing messages, which aim to connect with customers on an emotional level.\n",
    "\n",
    "- **Design & Aesthetics**: The design of the Fiat Dolcevita reflects Italian craftsmanship, with an emphasis on luxury and attention to detail. Marketing content highlights the car's elegant exterior, premium materials, and iconic styling, which are intended to evoke the sophistication of Italian fashion and culture.\n",
    "\n",
    "- **Technology & Features**: The Dolcevita is equipped with modern technology, including advanced infotainment systems and driver assistance features. Fiat emphasizes the balance between maintaining the car's classic appeal and integrating contemporary technological advancements.\n",
    "\n",
    "- **Build Quality & Materials**: Fiat's marketing emphasizes the use of high-quality, sustainable materials in the Dolcevita's construction. The car's build quality is portrayed as durable and luxurious, with a focus on eco-friendly options.\n",
    "\n",
    "- **Specifications & Performance**: Fiat positions the Dolcevita as a practical yet stylish car, with a focus on fuel efficiency and smooth urban driving. The marketing content also highlights the availability of hybrid models, aligning with Fiat's sustainability goals.\n",
    "\n",
    "This dataset was compiled from a variety of Fiat's official materials, including advertisements, press releases, and articles related to the Dolcevita, particularly from sources like Stellantis and MotorTrend.\n",
    "\n",
    "### Summary\n",
    "\n",
    "These two JSON files provide a comprehensive view of both customer perceptions and Fiat's marketing strategies for the Dolcevita. The customer review data focuses on real-world experiences and opinions, while the marketing content highlights Fiat's branding efforts and the features they promote. By comparing these two perspectives, one can gain insights into how well Fiat's marketing aligns with customer experiences and identify any gaps or opportunities for improvement in their branding strategy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
